{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 합성곱 신경망 (Convolutional Neural Network)\n",
    "\n",
    "- 사이토고키/개앞맵시, Chapter 7, 밑바닥부터 시작하는 딥러닝, 한빛미디어"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 7.1 전체 구조"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "완전연결 계층(Affine 계층)으로 이뤄진 네트워크의 예:\n",
    "<img src=\"./images/fig 7-1.png\" width=\"700\">\n",
    "\n",
    "CNN으로 이뤄진 네트워크의 예: 합성곱 계층과 풀링 계층 새로 추가\n",
    "<img src=\"./images/fig 7-2.png\" width=\"700\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 7.2 합성곱 계층"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 7.2.1 완전연결 계층의 문제점\n",
    "- 데이터의 형상이 무시 \n",
    "  - 3차원 데이터를 평평한 1차원 데이터로 평탄화해서 입력함 (예, MNIST (1,28,28) -> 784)\n",
    "- 이미지는 3차원(세로,가로,채널) 형상이며 공간적 정보가 담겨 있음 \n",
    "  - 공간적으로 가까운 픽셀은 값이 비슷함\n",
    "  - RGB의 각 채널은 서로 밀접하게 관련되어 있음\n",
    "  - 거리가 먼 픽셀끼리는 별 연관이 없음\n",
    "- 합성곱 계층은 형상을 유지\n",
    "  - 3차원 데이터를 입력 받아 다음 계층에 3차원 데이터로 전달 "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- 특징 맵 (feature map) : 합성곱 계층의 입출력 데이터\n",
    "  - 입력 특징 맵 : 합성곱 계층의 입력 데이터\n",
    "  - 출력 특징 맵 : 합성곱 계층의 출력 데이터"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 7.2.2 합성곱 연산"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- 이미지 처리에서는 필터 연산이라 불림 (공간 필터링)\n",
    "\n",
    "<img src=\"./images/fig 7-3.png\" width=\"500\">\n",
    "\n",
    "* 필터 = 마스크 = 커널"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "합성곱 연산의 계산 순서 : \n",
    "\n",
    "$$ \\text{첫번째 그림: }  1*2 + 2*0 + 3*1 + 0*0 + 1*1 + 2*2 + 3*1 + 0*0 + 1*2 = 15 $$\n",
    "\n",
    "<img src=\"./images/fig 7-4.png\" width=\"500\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**예) 이미지에서의 합성곱 연산** (https://alzi.tistory.com/83)\n",
    "\n",
    "$$ \n",
    "\\text{Convolution filter} =\n",
    "\\begin{bmatrix} \n",
    "   -1 & 0 & 1 \\\\\n",
    "   -1 & 0 & 1 \\\\\n",
    "   -1 & 0 & 1\n",
    "\\end{bmatrix}\n",
    "$$\n",
    "<img src=\"./images/conv_mask1_image.JPG\" width=\"600\">\n",
    "\n",
    "$$ \n",
    "\\text{Convolution filter} =\n",
    "\\begin{bmatrix} \n",
    "   1 & 0 & -1 \\\\\n",
    "   1 & 0 & -1 \\\\\n",
    "   1 & 0 & -1\n",
    "\\end{bmatrix}\n",
    "$$\n",
    "<img src=\"./images/conv_mask2_image.JPG\" width=\"600\">\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "합성곱 연산의 편향 :\n",
    "<img src=\"./images/fig 7-5.png\" width=\"600\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 7.2.3 패딩"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"./images/fig 7-6.png\" width=\"500\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 7.2.4 스트라이드"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "스트라이드가 2인 합성곱 연산 :\n",
    "<img src=\"./images/fig 7-7.png\" width=\"500\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "출력 크기 (OH,OW) : 입력 크기 (H,W), 필터 크기 (FH,FW), 패딩 P, 스트라이드 S\n",
    "\n",
    "<img src=\"./images/e 7.1.png\" width=\"200\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 7.2.5 3차원 데이터의 합성곱 연산"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "특징맵 형상 : (세로,가로,채널)\n",
    "<img src=\"./images/fig 7-8.png\" width=\"500\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "3차원 데이터의 합성곱 연산의 계산 순서 :\n",
    "<img src=\"./images/fig 7-9.png\" width=\"500\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 7.2.6 블록으로 생각하기"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"./images/fig 7-10.png\" width=\"500\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "여러 필터를 사용한 합성곱 연산의 예 :\n",
    "<img src=\"./images/fig 7-11.png\" width=\"500\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "합성곱 연산의 처리 흐름 (편향 추가) :\n",
    "<img src=\"./images/fig 7-12.png\" width=\"700\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 7.2.7 배치 처리"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"./images/fig 7-13.png\" width=\"700\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 7.3 풀링 계층"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- 풀링은 세로$\\cdot$가로 방향의 공간을 줄이는 연산이다"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "최대 풀링의 처리 순서 : 2$\\times$2 풀링, 스트라이드 2\n",
    "<img src=\"./images/fig 7-14.png\" width=\"600\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 7.3.1 풀링 계층의 특징"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- 학습해야 할 매개변수가 없다\n",
    "- 채널 수가 변하지 않는다\n",
    "- 입력의 변화에 영향을 적게 받는다 (강건하다) (아래 예에서 입력 데이터가 가로로 1원소 만큼 어긋나도 출력은 같다)\n",
    "<img src=\"./images/fig 7-16.png\" width=\"600\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 7.6 CNN 시각화하기"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "학습 전과 후의 1번째 층의 합성곱 계층의 가중치 : 검은색(0), 흰색(255)\n",
    "<img src=\"./images/fig 7-24.png\" width=\"600\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "가로 에지와 세로 에지에 반응하는 필터 :\n",
    "<img src=\"./images/fig 7-25.png\" width=\"600\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "CNN의 합성곱 계층에서 추출되는 정보 :\n",
    "<img src=\"./images/fig 7-26.png\" width=\"700\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Example of Convolutional Neural Network\n",
    "- MNIST data\n",
    "- 3 convolutional layers\n",
    "- 2 fully connected layers"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Settings\n",
    "### 1) Import required libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import torch.nn.init as init\n",
    "import torchvision.datasets as dset\n",
    "import torchvision.transforms as transforms\n",
    "from torch.utils.data import DataLoader\n",
    "from torch.autograd import Variable\n",
    "#from visdom import Visdom\n",
    "#viz = Visdom()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2) Set hyperparameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 100\n",
    "learning_rate = 0.0002\n",
    "num_epoch = 10"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Data\n",
    "\n",
    "### 1) Download Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "mnist_train = dset.MNIST(\"./\", train=True, transform=transforms.ToTensor(), target_transform=None, download=True)\n",
    "mnist_test = dset.MNIST(\"./\", train=False, transform=transforms.ToTensor(), target_transform=None, download=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2) Check Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([1, 28, 28]) 60000\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(torch.Size([1, 28, 28]), 10000)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(mnist_train.__getitem__(0)[0].size(), mnist_train.__len__())\n",
    "mnist_test.__getitem__(0)[0].size(), mnist_test.__len__()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3) Set DataLoader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_loader = torch.utils.data.DataLoader(mnist_train,batch_size=batch_size, shuffle=True,num_workers=2,drop_last=True)\n",
    "test_loader = torch.utils.data.DataLoader(mnist_test,batch_size=batch_size, shuffle=False,num_workers=2,drop_last=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Model & Optimizer\n",
    "\n",
    "### 1) CNN Model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Conv2d class :\n",
    "\n",
    "CLASS torch.nn.Conv2d(in_channels, out_channels, kernel_size, stride=1, padding=0, dilation=1, groups=1, bias=True, padding_mode='zeros')\n",
    "- input size: $(N, C_{\\text{in}}, H, W)$\n",
    "- output size: $(N, C_{\\text{out}}, H_{\\text{out}}, W_{\\text{out}})$\n",
    "- output value: \n",
    "$$ \\text{out} (N_i,C_{\\text{out}_j}) = \\text{bias} (C_{\\text{out}_j}) + \n",
    " \\sum_{k=0}^{C_{\\text{in}} - 1} \\text{weight} (C_{\\text{out}_j}, k) * \\text{input} (N_i, k)  $$\n",
    "- output shape: \n",
    "$$ H_{\\text{out}} = \\frac{H + 2P -KH}{S} + 1, \\text{where KH is kernel height, P is padding, S is stide} $$\n",
    "$$ W_{\\text{out}} = \\frac{W + 2P -KW}{S} + 1, \\text{where KW is kernel width, P is padding, S is stide} $$\n",
    "\n",
    "### MaxPool2d class :\n",
    "\n",
    "CLASS torch.nn.MaxPool2d(kernel_size, stride=None, padding=0, dilation=1, return_indices=False, ceil_mode=False)\n",
    "- input size: $(N, C_{\\text{in}}, H, W)$\n",
    "- output size: $(N, C_{\\text{out}}, H_{\\text{out}}, W_{\\text{out}})$\n",
    "- output shape: \n",
    "$$ H_{\\text{out}} = \\frac{H}{S}, \\text{Usually S = pooling window size} $$\n",
    "$$ W_{\\text{out}} = \\frac{W}{S}, \\text{Usually S = pooling window size} $$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "class CNN(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(CNN,self).__init__()\n",
    "        self.layer = nn.Sequential(\n",
    "            nn.Conv2d(1,16,5),    # in_channels=1, out_channels=16, kernel_size=5, stride=1, padding=0, dilation=1, groups=1, bias=True, padding_mode='zeros'\n",
    "                                  # input shape = (batch_size, channels, height, width) = (batch_size, 1, 28, 28)\n",
    "                                  # output shape = (batch_size, channels, height, width) = (batch_size, 16, 24, 24)\n",
    "            nn.ReLU(),\n",
    "            nn.Conv2d(16,32,5),    # in_channels=16, out_channels=32, kernel_size=5, ...\n",
    "                                   # output shape = (batch_size, channels, height, width) = (batch_size, 32, 20, 20)\n",
    "            nn.ReLU(),\n",
    "            nn.MaxPool2d(2,2),     # output shape = (batch_size, 32, 10, 10)\n",
    "            nn.Conv2d(32,64,5),    # in_channels=32, out_channels=64, kernel_size=5, ...\n",
    "                                   # output shape = (batch_size, channels, height, width) = (batch_size, 64, 6, 6)\n",
    "            nn.ReLU(),\n",
    "            nn.MaxPool2d(2,2)      # output shape = (batch_size, 64, 3, 3)\n",
    "        )\n",
    "        self.fc_layer = nn.Sequential(\n",
    "            nn.Linear(64*3*3,100),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(100,10)\n",
    "        )       \n",
    "        \n",
    "    def forward(self,x):\n",
    "        out = self.layer(x)\n",
    "        out = out.view(batch_size,-1)\n",
    "        out = self.fc_layer(out)\n",
    "\n",
    "        return out\n",
    "\n",
    "#model = CNN().cuda()\n",
    "model = CNN()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2) Loss func & Optimizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "loss_func = nn.CrossEntropyLoss()\n",
    "optimizer = torch.optim.SGD(model.parameters(), lr=learning_rate)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Train "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 0 tensor(2.3166, grad_fn=<NllLossBackward>)\n",
      "0 100 tensor(2.3131, grad_fn=<NllLossBackward>)\n",
      "0 200 tensor(2.3003, grad_fn=<NllLossBackward>)\n",
      "0 300 tensor(2.3085, grad_fn=<NllLossBackward>)\n",
      "0 400 tensor(2.3071, grad_fn=<NllLossBackward>)\n",
      "0 500 tensor(2.3028, grad_fn=<NllLossBackward>)\n",
      "1 0 tensor(2.3134, grad_fn=<NllLossBackward>)\n",
      "1 100 tensor(2.3055, grad_fn=<NllLossBackward>)\n",
      "1 200 tensor(2.3045, grad_fn=<NllLossBackward>)\n",
      "1 300 tensor(2.3114, grad_fn=<NllLossBackward>)\n",
      "1 400 tensor(2.3222, grad_fn=<NllLossBackward>)\n",
      "1 500 tensor(2.3067, grad_fn=<NllLossBackward>)\n",
      "2 0 tensor(2.2998, grad_fn=<NllLossBackward>)\n",
      "2 100 tensor(2.3128, grad_fn=<NllLossBackward>)\n",
      "2 200 tensor(2.2916, grad_fn=<NllLossBackward>)\n",
      "2 300 tensor(2.3082, grad_fn=<NllLossBackward>)\n",
      "2 400 tensor(2.3000, grad_fn=<NllLossBackward>)\n",
      "2 500 tensor(2.3064, grad_fn=<NllLossBackward>)\n",
      "3 0 tensor(2.3009, grad_fn=<NllLossBackward>)\n",
      "3 100 tensor(2.2941, grad_fn=<NllLossBackward>)\n",
      "3 200 tensor(2.3092, grad_fn=<NllLossBackward>)\n",
      "3 300 tensor(2.3062, grad_fn=<NllLossBackward>)\n",
      "3 400 tensor(2.3068, grad_fn=<NllLossBackward>)\n",
      "3 500 tensor(2.3156, grad_fn=<NllLossBackward>)\n",
      "4 0 tensor(2.3140, grad_fn=<NllLossBackward>)\n",
      "4 100 tensor(2.3135, grad_fn=<NllLossBackward>)\n",
      "4 200 tensor(2.2981, grad_fn=<NllLossBackward>)\n",
      "4 300 tensor(2.3007, grad_fn=<NllLossBackward>)\n",
      "4 400 tensor(2.2880, grad_fn=<NllLossBackward>)\n",
      "4 500 tensor(2.3032, grad_fn=<NllLossBackward>)\n",
      "5 0 tensor(2.2923, grad_fn=<NllLossBackward>)\n",
      "5 100 tensor(2.2822, grad_fn=<NllLossBackward>)\n",
      "5 200 tensor(2.2885, grad_fn=<NllLossBackward>)\n",
      "5 300 tensor(2.2965, grad_fn=<NllLossBackward>)\n",
      "5 400 tensor(2.2928, grad_fn=<NllLossBackward>)\n",
      "5 500 tensor(2.2979, grad_fn=<NllLossBackward>)\n",
      "6 0 tensor(2.3036, grad_fn=<NllLossBackward>)\n",
      "6 100 tensor(2.2950, grad_fn=<NllLossBackward>)\n",
      "6 200 tensor(2.2975, grad_fn=<NllLossBackward>)\n",
      "6 300 tensor(2.3045, grad_fn=<NllLossBackward>)\n",
      "6 400 tensor(2.2958, grad_fn=<NllLossBackward>)\n",
      "6 500 tensor(2.2946, grad_fn=<NllLossBackward>)\n",
      "7 0 tensor(2.3025, grad_fn=<NllLossBackward>)\n",
      "7 100 tensor(2.2974, grad_fn=<NllLossBackward>)\n",
      "7 200 tensor(2.2922, grad_fn=<NllLossBackward>)\n",
      "7 300 tensor(2.3058, grad_fn=<NllLossBackward>)\n",
      "7 400 tensor(2.2957, grad_fn=<NllLossBackward>)\n",
      "7 500 tensor(2.2912, grad_fn=<NllLossBackward>)\n",
      "8 0 tensor(2.2985, grad_fn=<NllLossBackward>)\n",
      "8 100 tensor(2.3041, grad_fn=<NllLossBackward>)\n",
      "8 200 tensor(2.2929, grad_fn=<NllLossBackward>)\n",
      "8 300 tensor(2.2974, grad_fn=<NllLossBackward>)\n",
      "8 400 tensor(2.2935, grad_fn=<NllLossBackward>)\n",
      "8 500 tensor(2.3067, grad_fn=<NllLossBackward>)\n",
      "9 0 tensor(2.2896, grad_fn=<NllLossBackward>)\n",
      "9 100 tensor(2.3054, grad_fn=<NllLossBackward>)\n",
      "9 200 tensor(2.3084, grad_fn=<NllLossBackward>)\n",
      "9 300 tensor(2.2942, grad_fn=<NllLossBackward>)\n",
      "9 400 tensor(2.2933, grad_fn=<NllLossBackward>)\n",
      "9 500 tensor(2.2900, grad_fn=<NllLossBackward>)\n",
      "Done!!!\n"
     ]
    }
   ],
   "source": [
    "for i in range(num_epoch):\n",
    "    for j,[image,label] in enumerate(train_loader):\n",
    "        #x = Variable(image).cuda()\n",
    "        x = Variable(image)\n",
    "        #y_= Variable(label).cuda()\n",
    "        y_= Variable(label)\n",
    "        \n",
    "        optimizer.zero_grad()\n",
    "        output = model.forward(x)\n",
    "        loss = loss_func(output,y_)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        \n",
    "        if j % 100 == 0:\n",
    "            print(i,j,loss)\n",
    "            \n",
    "print(\"Done!!!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#param_list = list(model.parameters())\n",
    "#print(param_list)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:6: UserWarning: volatile was removed and now has no effect. Use `with torch.no_grad():` instead.\n",
      "  \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy of Test Data: 90.79000091552734\n"
     ]
    }
   ],
   "source": [
    "correct = 0\n",
    "total = 0\n",
    "\n",
    "for image,label in test_loader:\n",
    "    #x = Variable(image,volatile=True).cuda()\n",
    "    x = Variable(image,volatile=True)\n",
    "    #y_= Variable(label).cuda()\n",
    "    y_= Variable(label)\n",
    "\n",
    "    output = model.forward(x)\n",
    "    _,output_index = torch.max(output,1)\n",
    "        \n",
    "    total += label.size(0)\n",
    "    correct += (output_index == y_).sum().float()\n",
    "    \n",
    "print(\"Accuracy of Test Data: {}\".format(100*correct/total))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
