{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Chapter 4. 신경망 학습 (Training Neural Network)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**실습문제**: 본 문서에 나오는 파이썬/넘파이 스크립트에서 None과 pass로 표시된 곳을 찾아서 적절한 코드로 대체하시오."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4.1 데이터에서 학습한다!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- 신경망(딥러닝)은 종단간 기계학습(end-to-end machine learning)을 가능하게 함\n",
    "- 입력 데이터에서 목표한 결과(출력)를 사람의 개입 없이 얻을 수 있음"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"fig-4-2.png\" width=\"800\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**훈련 데이터 (training data) vs 시험 데이터 (test data)**:\n",
    "\n",
    "- training data : 최적의 매개변수를 찾기위한 학습용\n",
    "- test data : 훈련한 신경망 모델을 평가 (모델의 범용능력을 평가)\n",
    "- overfitting(과적합) : 신경망 모델이 훈련 데이터만 잘 예측(분류)하고, 시험 데이터에 대해서는 잘 못하는 경우"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4.2 손실 함수 (Loss function)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4.2.1 평균 제곱 오차"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "한개의 데이터에 대한 손실함수:\n",
    "<img src=\"e-4.1.png\" width=\"250\">"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "y = np.array([0.1, 0.05, 0.6, 0.0, 0.05, 0.1, 0.0, 0.1, 0.0, 0.0])\n",
    "t = np.array([0, 0, 1, 0, 0, 0, 0, 0, 0, 0])    # one-hot encoding\n",
    "np.concatenate((y.reshape(1,-1), t.reshape(1,-1)))      #np.r_[y.reshape(1,-1),t.reshape(1,-1)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def mean_squared_error(y,t):\n",
    "    return 0.5 * np.sum((y-t)**2)     # 여기에 None 대신에 적절한 코드를 입력하시오."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "t = np.array([0, 0, 1, 0, 0, 0, 0, 0, 0, 0])    # one-hot encoding\n",
    "\n",
    "y = np.array([0.1, 0.05, 0.6, 0.0, 0.05, 0.1, 0.0, 0.1, 0.0, 0.0])      # '2'일 확률이 가장 높다고 추정함 (0.6)\n",
    "mean_squared_error(y,t)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y = np.array([0.1, 0.05, 0.1, 0.0, 0.05, 0.1, 0.0, 0.6, 0.0, 0.0])      # '7'일 확률이 가장 높다고 추정함 (0.6)\n",
    "mean_squared_error(y,t)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4.2.2 교차 엔트로피 오차"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "한개의 데이터에 대한 손실함수:\n",
    "<img src=\"e-4.2.png\" width=\"250\">"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def cross_entropy_error(y,t):\n",
    "    delta = 1e-7    # 10^(-7)\n",
    "    return -np.sum(t * np.log(y+delta))      # log = log_e    # 여기에 None 대신에 적절한 코드를 입력하시오."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "t = np.array([0, 0, 1, 0, 0, 0, 0, 0, 0, 0])    # one-hot encoding\n",
    "\n",
    "y = np.array([0.1, 0.05, 0.6, 0.0, 0.05, 0.1, 0.0, 0.1, 0.0, 0.0])      # '2'일 확률이 가장 높다고 추정함 (0.6)\n",
    "cross_entropy_error(y,t)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y = np.array([0.1, 0.05, 0.1, 0.0, 0.05, 0.1, 0.0, 0.6, 0.0, 0.0])      # '7'일 확률이 가장 높다고 추정함 (0.6)\n",
    "cross_entropy_error(y,t)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4.2.3 미니배치 학습"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "N 개의 데이터에 대한 손실함수:\n",
    "<img src=\"e-4.3.png\" width=\"300\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "미니배치(mini-batch) 학습: 전체 데이터 중에 일부만 골라 학습 (예, 60,000 장의 훈련 데이터 중에서 100장을 무작위로 뽑아서 100장만을 사용하여 학습 함)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys, os\n",
    "sys.path.append(os.pardir)\n",
    "import numpy as np\n",
    "from dataset.mnist import load_mnist\n",
    "\n",
    "(x_train, t_train), (x_test, t_test) = \\\n",
    "    load_mnist(normalize=True, one_hot_label=True)\n",
    "\n",
    "print(x_train.shape)    # (60000, 784)\n",
    "print(t_train.shape)    # (60000, 10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "60,000 개의 훈련 데이터로부터 10개만 무작위로 골라 낼려면?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "np.random.choice(60000,10)      # 0 ~ 59999 사이의 정수 중에 무작위로 10개를 골라냄"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "np.random.choice()로부터 나온 10개의 인덱스를 이용해 x_train과 t_train으로부터 10개의 데이터를 뽑아 냄:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_size = x_train.shape[0]\n",
    "batch_size = 10\n",
    "batch_mask = np.random.choice(train_size, batch_size)\n",
    "x_batch = x_train[batch_mask]\n",
    "t_batch = t_train[batch_mask]\n",
    "#x_batch, t_batch"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4.2.4 배치용 교차 엔트로피 오차 구현하기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def cross_entropy_error(y,t):    # t가 one-hot encoding인 경우만을 가정함, t가 숫자 레이블인 경우는 교재 참조\n",
    "    if y.ndim == 1:      # 데이터가 하나만 있는 경우\n",
    "        t = t.reshape(1, t.size)\n",
    "        y = y.reshape(1, y.size)\n",
    "        \n",
    "    batch_size = y.shape[0]\n",
    "    delta = 1e-7\n",
    "    return -np.sum(t * np.log(y+delta)) / batch_size    # np.sum() 하나로 2차원 행렬 t와 np.log(y)의 모든 원소 간의 곱을 더함 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "t = np.array([0, 0, 1, 0, 0, 0, 0, 0, 0, 0])    # one-hot encoding\n",
    "\n",
    "y = np.array([0.1, 0.05, 0.6, 0.0, 0.05, 0.1, 0.0, 0.1, 0.0, 0.0])      # '2'일 확률이 가장 높다고 추정함 (0.6)\n",
    "cross_entropy_error(y,t)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4.3 수치 미분"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "전방차분:\n",
    "$$ \\frac{df(x)}{dx} = \\lim\\limits_{h \\to 0} \\frac{f(x+h)-f(x)}{h} $$\n",
    "중앙차분:\n",
    "$$ \\frac{df(x)}{dx} = \\lim\\limits_{h \\to 0} \\frac{f(x+h)-f(x-h)}{2h} $$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "수치미분 구현시에는 전방 차분 보다는 중앙 차분으로 하는 것이 오차를 줄일 수 있음"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def numerical_diff(f,x):    # 고차 함수 : 함수를 인자로 받는 함수\n",
    "    h = 1e-4    # 0.0001\n",
    "    return (f(x+h) - f(x-h)) / (2*h)    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**수치미분의 예**:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def function_1(x):\n",
    "    return 0.01*x**2 + 0.1*x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "numerical_diff(function_1, 5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "numerical_diff(function_1, 10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**편미분과 gradient**:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def function_2(x):\n",
    "    '''''\n",
    "    if x.ndim == 1:\n",
    "        return np.sum(x**2)\n",
    "    else:\n",
    "        return np.sum(x**2, axis=1)\n",
    "    '''''\n",
    "    return x[0]**2 + x[1]**2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"fig-4-8.png\" width=\"500\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**실습문제**: 위의 그래프를 출력하는 파이썬/넘파이 스크립트를 작성하시오."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from mpl_toolkits.mplot3d import Axes3D\n",
    "\n",
    "x0 = np.linspace(-3, 3, 30)     # my insert\n",
    "x1 = np.linspace(-3, 3, 30)\n",
    "xn = x0.shape[0]\n",
    "X0, X1 = np.meshgrid(x0, x1)\n",
    "y = np.zeros((len(x0),len(x1)))\n",
    "X = np.zeros(2)\n",
    "for i1 in range(xn):\n",
    "    for i0 in range(xn):\n",
    "        X[0] = X0[i1,i0]\n",
    "        X[1] = X1[i1,i0]\n",
    "        y[i1,i0] = function_2(X)\n",
    "fig = plt.figure(figsize=(10, 7))\n",
    "ax = fig.gca(projection='3d')\n",
    "ax.plot_surface(X0, X1, y, rstride=1, cstride=1, alpha=0.3,\n",
    "                color='w', edgecolor='black')\n",
    "ax.view_init(25, -115) \n",
    "plt.xlabel(\"X0\")\n",
    "plt.ylabel(\"X1\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "gradient at $(x_0=3, x_1=4) : (\\frac{\\partial f}{\\partial x_0},\\frac{\\partial f}{\\partial x_1})$\n",
    "- 모든 편미분을 벡터화 한 것"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pylab as plt\n",
    "from mpl_toolkits.mplot3d import Axes3D\n",
    "\n",
    "#def _numerical_gradient_no_batch(f, x):\n",
    "def numerical_gradient(f, x):\n",
    "    h = 1e-4  # 0.0001\n",
    "    grad = np.zeros_like(x)    # x와 형상이 같고 그 원소가 모두 0인 배열을 생성함\n",
    "    \n",
    "    for idx in range(x.size):\n",
    "        tmp_val = x[idx]\n",
    "        \n",
    "        x[idx] = float(tmp_val) + h\n",
    "        fxh1 = f(x)  # f(x+h)\n",
    "        #print(fxh1)\n",
    "        \n",
    "        x[idx] = tmp_val - h \n",
    "        fxh2 = f(x)  # f(x-h)\n",
    "        #print(fxh2)\n",
    "        \n",
    "        grad[idx] = (fxh1 - fxh2) / (2*h)\n",
    "        \n",
    "        x[idx] = tmp_val  # 값 복원\n",
    "\n",
    "        print(x[idx], grad[idx])\n",
    "\n",
    "    return grad"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "numerical_gradient(function_2, np.array([3.0, 4.0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "numerical_gradient(function_2, np.array([0.0, 2.0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "numerical_gradient(function_2, np.array([3.0, 0.0]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "gradient를 그려보기:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"fig-4-9.png\" width=\"500\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**실습문제**: 위의 그림과 같이 gradient를 그리는 파이썬 스크립트를 작성하시오."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pylab as plt\n",
    "from mpl_toolkits.mplot3d import Axes3D\n",
    "\n",
    "def _numerical_gradient_no_batch(f, x):\n",
    "    h = 1e-4  # 0.0001\n",
    "    grad = np.zeros_like(x)\n",
    "    \n",
    "    for idx in range(x.size):\n",
    "        tmp_val = x[idx]\n",
    "        x[idx] = float(tmp_val) + h\n",
    "        fxh1 = f(x) \n",
    "        x[idx] = tmp_val - h \n",
    "        fxh2 = f(x)\n",
    "        grad[idx] = (fxh1 - fxh2) / (2*h)\n",
    "        \n",
    "        x[idx] = tmp_val          \n",
    "    return grad\n",
    "def numerical_gradient(f, X):\n",
    "    if X.ndim == 1:\n",
    "        return _numerical_gradient_no_batch(f, X)\n",
    "    else:\n",
    "        grad = np.zeros_like(X)\n",
    "        \n",
    "        for idx, x in enumerate(X):\n",
    "            grad[idx] = _numerical_gradient_no_batch(f, x)\n",
    "        \n",
    "        return grad\n",
    "def function_2(x):\n",
    "    if x.ndim == 1:\n",
    "        return np.sum(x**2)\n",
    "    else:\n",
    "        return np.sum(x**2, axis=1)\n",
    "def tangent_line(f, x):\n",
    "    d = numerical_gradient(f, x)\n",
    "    #print(d)\n",
    "    y = f(x) - d*x\n",
    "    return lambda t: d*t + y\n",
    "if __name__ == '__main__':\n",
    "    x0 = np.arange(-2, 2.5, 0.25)\n",
    "    x1 = np.arange(-2, 2.5, 0.25)\n",
    "    X, Y = np.meshgrid(x0, x1)\n",
    "    \n",
    "    X = X.flatten()\n",
    "    Y = Y.flatten()\n",
    "\n",
    "    grad = numerical_gradient(function_2, np.array([X, Y]).T).T\n",
    "\n",
    "    plt.figure()\n",
    "    plt.quiver(X, Y, -grad[0], -grad[1],  angles=\"xy\",color=\"#666666\")\n",
    "    plt.xlim([-2, 2])\n",
    "    plt.ylim([-2, 2])\n",
    "    plt.xlabel('x0')\n",
    "    plt.ylabel('x1')\n",
    "    plt.grid()\n",
    "    plt.draw()\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4.4 경사 하강법 (gradient descent)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"e-4.7.png\" width=\"200\">     $\\eta$: 학습률(learning rate)\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**실습문제**: 경사 하강법으로 아래 그림과 같이 $f(x_0,x_1)=x_0^2+x_1^2$의 최솟값을 구하라."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"fig-4-10.png\" width=\"500\">"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pylab as plt\n",
    "def gradient_descent(f, init_x, lr=0.01, step_num=100):\n",
    "    x = init_x\n",
    "    x_history = []\n",
    "\n",
    "    for i in range(step_num):\n",
    "        x_history.append( x.copy() )\n",
    "\n",
    "        grad = numerical_gradient(f, x)\n",
    "        x -= lr * grad\n",
    "\n",
    "    return x, np.array(x_history)\n",
    "\n",
    "def function_2(x):\n",
    "    return x[0]**2 + x[1]**2\n",
    "\n",
    "init_x = np.array([-3.0, 4.0])    \n",
    "\n",
    "lr = 0.1\n",
    "step_num = 20\n",
    "x, x_history = gradient_descent(function_2, init_x, lr=lr, step_num=step_num)\n",
    "\n",
    "plt.plot(x_history[:,0], x_history[:,1], 'o')\n",
    "\n",
    "x0 = np.linspace(-5, 5, 100)     \n",
    "x1 = np.linspace(-5, 5, 100)\n",
    "xn = x0.shape[0]\n",
    "X0, X1 = np.meshgrid(x0, x1)\n",
    "y = np.zeros((len(x0),len(x1)))\n",
    "X = np.zeros(2)\n",
    "for i1 in range(xn):\n",
    "    for i0 in range(xn):\n",
    "        X[0] = X0[i1,i0]\n",
    "        X[1] = X1[i1,i0]\n",
    "        y[i1,i0] = function_2(X)\n",
    "\n",
    "plt.figure(1, figsize=(5, 5))\n",
    "cont = plt.contour(X0, X1, y, levels=(0.25, 1, 4, 9, 16), colors='black', alpha=0.5, linestyles='dashed')    \n",
    "plt.xlim(-4.5, 4.5)\n",
    "plt.ylim(-4.5, 4.5)\n",
    "plt.xlabel(\"X0\")\n",
    "plt.ylabel(\"X1\")\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "학습률이 너무 크면:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 학습률이 너무 큰 예 : lr=10.0\n",
    "init_x = np.array([-3.0, 4.0])\n",
    "#gradient_descent(function_2, init_x=init_x, lr=10.0, step_num=100)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "학습률이 너무 작으면:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 학습률이 너무 작은 예 : lr=1e-10\n",
    "init_x = np.array([-3.0, 4.0])\n",
    "#gradient_descent(function_2, init_x=init_x, lr=1e-10, step_num=100)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**파라미터 vs 하이퍼 파라미터**:\n",
    "\n",
    "- 파라미터 : W, b - 학습 알고리즘에 의해서 자동 획득\n",
    "- 하이퍼 파라미터 : 학습률, 반복횟수, 미니배치 크기 등 - 사람이 직접 설정"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4.4.2 신경망에서의 기울기"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"e-4.8.png\" width=\"250\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**간단한 신경망 simpleNet 구현 예:** 1 layer NN\n",
    "\n",
    "- 입력 X = [x0,x1]\n",
    "- 중간 출력 Z = [z1,z2,z3] = X*W      where W = 2x3 matrix\n",
    "- 출력 Y = [y0,y1,y2]  = softmax(Z)\n",
    "- 정답 T = [t0,t1,t2]      => one-hot encoding"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "simpleNet 클래스 정의:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# coding: utf-8\n",
    "import sys, os\n",
    "sys.path.append(os.pardir)  # 부모 디렉토리의 파일을 가져올 수 있도록 설정\n",
    "import numpy as np\n",
    "from common.functions import softmax, cross_entropy_error    # common library 사용\n",
    "from common.gradient import numerical_gradient        # common library 사용\n",
    "\n",
    "class simpleNet:\n",
    "    def __init__(self):\n",
    "        self.W = np.random.randn(2,3)        # 가중치 매개변수 초기화 - 정규분포로 초기화\n",
    "\n",
    "    def predict(self, x):\n",
    "        return np.dot(x, self.W)\n",
    "\n",
    "    def loss(self, x, t):\n",
    "        z = self.predict(x)\n",
    "        y = softmax(z)\n",
    "        loss = cross_entropy_error(y, t)\n",
    "        return loss\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "simpleNet 테스트:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "net = simpleNet()\n",
    "print(net.W)    # 가중치 매개변수 출력"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Prediction:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "x = np.array([0.6, 0.9])\n",
    "p = net.predict(x)\n",
    "print(p)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "np.argmax(p)    # 최대값의 인덱스"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Loss 계산:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "t = np.array([0, 0, 1])    # 정답 레이블\n",
    "net.loss(x, t)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "기울기(gradient) 계산:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "def f(W):  # 인수 W는 dummy로 만든 것?\n",
    "           # net.loss() 함수는 W에 따라서 그 값이 달라짐. 따라서 f()는 W의 함수임\n",
    "    return net.loss(x, t)\n",
    "\n",
    "dW = numerical_gradient(f, net.W)    # 고차함수 : 함수의 인자로 함수를 넘김\n",
    "print(dW)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "위의 함수 f를 람다 식으로 표현하면:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "f = lambda w: net.loss(x, t)\n",
    "dW = numerical_gradient(f, net.W)\n",
    "print(dW)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**간단한 신경망 simpleNet 구현 예 끝:** \n",
    "\n",
    "- 이 예제에서는 신경망의 기울기(gradient) 까지만 구함. \n",
    "- 경사하강법에 따라 가중치 매개변수를 갱신하는 학습 알고리즘은 다음 절에서 설명함."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**실습문제**: MNIST 데이터에 대하여 1층 신경망을 구성하고 매개변수를 학습시켜서 학습시간과 정확도를 측정하시오. 머신러닝 교과서 '6장 Logistic Regression'과 본 교재 4.5절 2층 신경망 구현 내용을 참조하여 위의 simpleNet을 적절히 수정하여 구현하시오."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "MNIST에 대한 OneLayerNet 클래스 정의: (머신러닝 교과서 '6장 Logistic Regression, 6.3절 2차원 입력 3클래스 분류'과 본 교재 4.5절 2층 신경망 구현 내용 참조)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Neural network configuration :\n",
    "- input layer neurons: 784\n",
    "- output layer neurons: 10"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$$ A^{(1)} = X \\cdot W^{(1)} + B^{(1)} $$\n",
    "\n",
    "$$ \\begin{pmatrix} a_1^{(1)} & \\cdots & a_{10}^{(1)} \\end{pmatrix} = \n",
    "   \\begin{pmatrix} x_1 & \\cdots & x_{784} \\end{pmatrix} \n",
    "   \\begin{pmatrix} w_{1,1}^{(1)} & \\cdots & w_{10,1}^{(1)} \\\\ \\vdots & \\ddots & \\vdots \\\\ w_{1,784}^{(1)} & \\cdots & w_{10,784}^{(1)} \\end{pmatrix}\n",
    "   + \\begin{pmatrix} b_1^{(1)} & \\cdots & b_{10}^{(1)} \\end{pmatrix} $$\n",
    "   \n",
    "$$ Y = softmax(A^{(1)}) $$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "학습해야 할 매개변수 개수:\n",
    "\n",
    "- W1 = 784*10, b1 = 10, Total = 7850"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "OneLayerNet 클래스 정의:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys, os\n",
    "sys.path.append(os.pardir)\n",
    "import numpy as np\n",
    "from common.functions import softmax, cross_entropy_error  \n",
    "from common.gradient import numerical_gradient   \n",
    "\n",
    "class OneLayerNet:\n",
    "    def __init__(self, input_size, output_size, weight_init_std=0.01):\n",
    "        self.params = {}\n",
    "        self.params['W1'] = weight_init_std * np.random.randn(input_size, output_size)\n",
    "        self.params['b1'] = np.zeros(output_size)\n",
    "        \n",
    "    def predict(self, x):\n",
    "        W1 = self.params['W1']\n",
    "        b1 = self.params['b1']    \n",
    "        a1 = np.dot(x, W1) + b1\n",
    "        y = softmax(a1)        \n",
    "        return y        \n",
    "\n",
    "    def loss(self, x, t):\n",
    "        y = self.predict(x)\n",
    "        loss = cross_entropy_error(y, t)\n",
    "        return loss\n",
    "\n",
    "    def accuracy(self, x, t):\n",
    "        y = self.predict(x)\n",
    "        y = np.argmax(y, axis=1)\n",
    "        t = np.argmax(t, axis=1)        \n",
    "        accuracy = np.sum(y == t) / float(x.shape[0])\n",
    "        return accuracy\n",
    "\n",
    "    def numerical_gradient(self, x, t):  \n",
    "        loss_W = lambda W: self.loss(x, t)        \n",
    "        grads = {}\n",
    "        print(\"Call numerical_gradient for W1\\n\") \n",
    "        grads['W1'] = numerical_gradient(loss_W, self.params['W1'])\n",
    "        print(\"Call numerical_gradient for b1\\n\")    \n",
    "        grads['b1'] = numerical_gradient(loss_W, self.params['b1'])\n",
    "        return grads\n",
    "        \n",
    "    def gradient(self, x, t): \n",
    "        W1 = self.params['W1']\n",
    "        b1 = self.params['b1']\n",
    "        grads = {}\n",
    "        \n",
    "        batch_num = x.shape[0]        \n",
    "        a1 = np.dot(x, W1) + b1\n",
    "        y = softmax(a1)        \n",
    "        dy = (y - t) / batch_num\n",
    "        grads['W1'] = np.dot(x.T, dy)\n",
    "        grads['b1'] = np.sum(dy, axis=0)\n",
    "        return grads"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "OneLayerNet 테스트:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "net = OneLayerNet(input_size=784, output_size=10)\n",
    "print(\"net.params['W1'].shape = \", net.params['W1'].shape)\n",
    "print(\"net.params['b1'].shape = \", net.params['b1'].shape) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Prediction:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = np.random.rand(100, 784) \n",
    "y = net.predict(x)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Gradient 계산:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "x = np.random.rand(100, 784)   \n",
    "t = np.random.rand(100, 10)  \n",
    "\n",
    "grads = net.numerical_gradient(x, t) \n",
    "    \n",
    "print(\"grads['W1'].shape = \", grads['W1'].shape)  \n",
    "print(\"grads['b1'].shape = \", grads['b1'].shape) \n",
    "\n",
    "print(\"grads['W1'] = \", grads['W1'])    \n",
    "print(\"grads['b1'] = \", grads['b1'])    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "미니배치 학습 구현하기:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import sys, os\n",
    "sys.path.append(os.pardir)\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from dataset.mnist import load_mnist\n",
    "(x_train, t_train), (x_test, t_test) = load_mnist(normalize=True, one_hot_label=True)\n",
    "\n",
    "onelayernet = OneLayerNet(input_size=784, output_size=10)\n",
    "\n",
    "iters_num = 10000\n",
    "train_size = x_train.shape[0]\n",
    "batch_size = 100\n",
    "learning_rate = 0.1\n",
    "\n",
    "train_loss_list = []\n",
    "\n",
    "for i in range(iters_num):\n",
    "    \n",
    "    batch_mask = np.random.choice(train_size, batch_size)    \n",
    "    x_batch = x_train[batch_mask]\n",
    "    t_batch = t_train[batch_mask]\n",
    "    \n",
    "    grad = onelayernet.gradient(x_batch, t_batch)    \n",
    "    \n",
    "    for key in ('W1', 'b1'):\n",
    "        onelayernet.params[key] -= learning_rate * grad[key]\n",
    "    \n",
    "    loss = onelayernet.loss(x_batch, t_batch)\n",
    "    train_loss_list.append(loss)\n",
    "\n",
    "print(\"Mini-batch training Done!!!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "시험 데이터로 평가하기:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "import sys, os\n",
    "sys.path.append(os.pardir)\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from dataset.mnist import load_mnist\n",
    "\n",
    "(x_train, t_train), (x_test, t_test) = load_mnist(normalize=True, one_hot_label=True)\n",
    "\n",
    "onelayernet = OneLayerNet(input_size=784, output_size=10)\n",
    "\n",
    "iters_num = 10000 \n",
    "train_size = x_train.shape[0]\n",
    "batch_size = 100\n",
    "learning_rate = 0.1\n",
    "\n",
    "train_loss_list = []\n",
    "train_acc_list = []\n",
    "test_acc_list = []\n",
    "\n",
    "iter_per_epoch = max(train_size / batch_size, 1)\n",
    "for i in range(iters_num):\n",
    "    batch_mask = np.random.choice(train_size, batch_size)\n",
    "    x_batch = x_train[batch_mask]\n",
    "    t_batch = t_train[batch_mask]\n",
    "    \n",
    "    grad = onelayernet.gradient(x_batch, t_batch)\n",
    "    \n",
    "    for key in ('W1', 'b1'):\n",
    "        onelayernet.params[key] -= learning_rate * grad[key]\n",
    "    \n",
    "    loss = onelayernet.loss(x_batch, t_batch)\n",
    "    train_loss_list.append(loss)\n",
    "    \n",
    "    if i % iter_per_epoch == 0:\n",
    "        train_acc = onelayernet.accuracy(x_train, t_train)\n",
    "        test_acc = onelayernet.accuracy(x_test, t_test)\n",
    "        train_acc_list.append(train_acc)\n",
    "        test_acc_list.append(test_acc)\n",
    "        print(\"i = \" + str(i) + \" | train acc, test acc | \" + str(train_acc) + \", \" + str(test_acc))\n",
    "\n",
    "markers = {'train': 'o', 'test': 's'}\n",
    "x = np.arange(len(train_acc_list))\n",
    "plt.plot(x, train_acc_list, label='train acc')\n",
    "plt.plot(x, test_acc_list, label='test acc', linestyle='--')\n",
    "plt.xlabel(\"epochs\")\n",
    "plt.ylabel(\"accuracy\")\n",
    "plt.ylim(0, 1.0)\n",
    "plt.legend(loc='lower right')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "눈으로 확인하기:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from PIL import Image\n",
    "from matplotlib.pyplot import imshow\n",
    "%matplotlib inline  \n",
    "\n",
    "def img_show(img):\n",
    "    pil_img = Image.fromarray(np.uint8(img))\n",
    "    imshow(np.asarray(pil_img)) \n",
    "\n",
    "test_size = x_test.shape[0]\n",
    "test_mask = np.random.choice(test_size, 10)\n",
    "print(\"test_mask = \", test_mask)\n",
    "\n",
    "x = x_test[test_mask]\n",
    "t = t_test[test_mask]\n",
    "y = onelayernet.predict(x)\n",
    "\n",
    "y = np.argmax(y, axis=1)\n",
    "t = np.argmax(t, axis=1)\n",
    "\n",
    "print(\"y =\", end=\" \")\n",
    "for i in range(10):\n",
    "    label = y[i]\n",
    "    print(label, end=\"            \") \n",
    "\n",
    "print(\"t =\", end=\" \")\n",
    "for i in range(10):\n",
    "    label = t[i]\n",
    "    print(label, end=\"            \") \n",
    "        \n",
    "plt.figure(figsize=(15, 2))\n",
    "plt.subplots_adjust(wspace=0.5, hspace=0.5) \n",
    "for i in range(10):\n",
    "    plt.subplot(1, 10, i + 1)\n",
    "    img = x[i]*256      \n",
    "    img = img.reshape(28, 28)  \n",
    "    img_show(img)\n",
    "plt.show()   "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4.5 2층 신경망에 대한 학습 알고리즘 구현하기"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### <center> $w_{ij} = w_{ij} - \\eta \\frac{\\partial L}{\\partial w_{ij}}$ </center>\n",
    "\n",
    "- 데이터를 미니배치로 무작위로 선정\n",
    "- 확률적 경사 하강법 (SGD: Stochastic Gradient Descent) : 확률적으로 무작위로 골라낸 데이터에 대해 수행하는 경사하강법\n",
    "\n",
    "**신경망 학습의 절차**:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"p180.jpg\" width=\"800\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4.5.1 2층 신경망 클래스 구현하기"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Neural network configuration :\n",
    "- input layer neurons: 784\n",
    "- hidden layer neurons: 50\n",
    "- output layer neurons: 10"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$$ A^{(1)} = X \\cdot W^{(1)} + B^{(1)} $$\n",
    "\n",
    "$$ \\begin{pmatrix} a_1^{(1)} & \\cdots & a_{50}^{(1)} \\end{pmatrix} = \n",
    "   \\begin{pmatrix} x_1 & \\cdots & x_{784} \\end{pmatrix} \n",
    "   \\begin{pmatrix} w_{1,1}^{(1)} & \\cdots & w_{50,1}^{(1)} \\\\ \\vdots & \\ddots & \\vdots \\\\ w_{1,784}^{(1)} & \\cdots & w_{50,784}^{(1)} \\end{pmatrix}\n",
    "   + \\begin{pmatrix} b_1^{(1)} & \\cdots & b_{50}^{(1)} \\end{pmatrix} $$\n",
    "   \n",
    "$$ Z^{(1)} = sigmoid(A^{(1)}) $$\n",
    "   \n",
    "$$ A^{(2)} = Z^{(1)} \\cdot W^{(2)} + B^{(2)} $$\n",
    "\n",
    "$$ \\begin{pmatrix} a_1^{(2)} & \\cdots & a_{10}^{(2)} \\end{pmatrix} = \n",
    "   \\begin{pmatrix} z_1^{(1)} & \\cdots & z_{50}^{(1)} \\end{pmatrix} \n",
    "   \\begin{pmatrix} w_{1,1}^{(2)} & \\cdots & w_{10,1}^{(2)} \\\\ \\vdots & \\ddots & \\vdots \\\\ w_{1,50}^{(2)} & \\cdots & w_{10,50}^{(2)} \\end{pmatrix}\n",
    "   + \\begin{pmatrix} b_1^{(2)} & \\cdots \\ b_{10}^{(2)} \\end{pmatrix} $$\n",
    "   \n",
    "$$ Y = softmax(A^{(2)}) $$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "학습해야 할 매개변수 개수:\n",
    "\n",
    "- W1 = 784*50, b1 = 50\n",
    "- W2 = 50*10,  b2 = 10\n",
    "- Total = 39,760"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "TwoLayerNet 클래스 정의:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# coding: utf-8\n",
    "import sys, os\n",
    "sys.path.append(os.pardir)  # 부모 디렉토리의 파일을 가져올 수 있도록 설정\n",
    "from common.functions import *\n",
    "from common.gradient import numerical_gradient      # 2019/10/13 use numerical_gradient in common\n",
    "\n",
    "class TwoLayerNet:\n",
    "\n",
    "    def __init__(self, input_size, hidden_size, output_size, weight_init_std=0.01):\n",
    "        # 가중치 초기화\n",
    "        self.params = {}\n",
    "        self.params['W1'] = weight_init_std * np.random.randn(input_size, hidden_size)\n",
    "        self.params['b1'] = np.zeros(hidden_size)\n",
    "        self.params['W2'] = weight_init_std * np.random.randn(hidden_size, output_size)\n",
    "        self.params['b2'] = np.zeros(output_size)\n",
    "\n",
    "    def predict(self, x):\n",
    "        W1, W2 = self.params['W1'], self.params['W2']\n",
    "        b1, b2 = self.params['b1'], self.params['b2']\n",
    "    \n",
    "        a1 = np.dot(x, W1) + b1\n",
    "        z1 = sigmoid(a1)\n",
    "        a2 = np.dot(z1, W2) + b2\n",
    "        y = softmax(a2)\n",
    "        \n",
    "        return y\n",
    "        \n",
    "    # x : 입력 데이터, t : 정답 레이블\n",
    "    def loss(self, x, t):\n",
    "        y = self.predict(x)\n",
    "        \n",
    "        return cross_entropy_error(y, t)\n",
    "    \n",
    "    def accuracy(self, x, t):\n",
    "        y = self.predict(x)\n",
    "        y = np.argmax(y, axis=1)\n",
    "        t = np.argmax(t, axis=1)\n",
    "        \n",
    "        accuracy = np.sum(y == t) / float(x.shape[0])\n",
    "        return accuracy\n",
    "        \n",
    "    # x : 입력 데이터, t : 정답 레이블\n",
    "    def numerical_gradient(self, x, t):\n",
    "        loss_W = lambda W: self.loss(x, t)\n",
    "        \n",
    "        grads = {}\n",
    "        print(\"Call numerical_gradient for W1\\n\")    # 2019/10/13 for test\n",
    "        grads['W1'] = numerical_gradient(loss_W, self.params['W1'])\n",
    "        print(\"Call numerical_gradient for b1\\n\")    # 2019/10/13 for test\n",
    "        grads['b1'] = numerical_gradient(loss_W, self.params['b1'])\n",
    "        print(\"Call numerical_gradient for W2\\n\")    # 2019/10/13 for test\n",
    "        grads['W2'] = numerical_gradient(loss_W, self.params['W2'])\n",
    "        print(\"Call numerical_gradient for b2\\n\")    # 2019/10/13 for test\n",
    "        grads['b2'] = numerical_gradient(loss_W, self.params['b2'])\n",
    "        \n",
    "        return grads\n",
    "        \n",
    "    def gradient(self, x, t):\n",
    "        W1, W2 = self.params['W1'], self.params['W2']\n",
    "        b1, b2 = self.params['b1'], self.params['b2']\n",
    "        grads = {}\n",
    "        \n",
    "        batch_num = x.shape[0]\n",
    "        \n",
    "        # forward\n",
    "        a1 = np.dot(x, W1) + b1\n",
    "        z1 = sigmoid(a1)\n",
    "        a2 = np.dot(z1, W2) + b2\n",
    "        y = softmax(a2)\n",
    "        \n",
    "        # backward\n",
    "        dy = (y - t) / batch_num\n",
    "        grads['W2'] = np.dot(z1.T, dy)\n",
    "        grads['b2'] = np.sum(dy, axis=0)\n",
    "        \n",
    "        dz1 = np.dot(dy, W2.T)\n",
    "        da1 = sigmoid_grad(a1) * dz1\n",
    "        grads['W1'] = np.dot(x.T, da1)\n",
    "        grads['b1'] = np.sum(da1, axis=0)\n",
    "\n",
    "        return grads\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "TwoLayerNet 클래스가 사용하는 변수와 메소드:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"tab-4-1.jpg\" width=\"800\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "TwoLayerNet 테스트:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "net.params['W1'].shape =  (784, 50)\n",
      "net.params['b1'].shape =  (50,)\n",
      "net.params['W2'].shape =  (50, 10)\n",
      "net.params['b2'].shape =  (10,)\n"
     ]
    }
   ],
   "source": [
    "net = TwoLayerNet(input_size=784, hidden_size=50, output_size=10)\n",
    "print(\"net.params['W1'].shape = \", net.params['W1'].shape)    # (784, 50)\n",
    "print(\"net.params['b1'].shape = \", net.params['b1'].shape)    # (50,)\n",
    "print(\"net.params['W2'].shape = \", net.params['W2'].shape)    # (50, 10)\n",
    "print(\"net.params['b2'].shape = \", net.params['b2'].shape)    # (10,)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "prediction:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = np.random.rand(100, 784)    # 더미 입력 데이터 (100장 분량)\n",
    "y = net.predict(x)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "gradient 계산:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Call numerical_gradient for W1\n",
      "\n",
      "Call numerical_gradient for b1\n",
      "\n",
      "Call numerical_gradient for W2\n",
      "\n",
      "Call numerical_gradient for b2\n",
      "\n",
      "grads['W1'].shape =  (784, 50)\n",
      "grads['b1'].shape =  (50,)\n",
      "grads['W2'].shape =  (50, 10)\n",
      "grads['b2'].shape =  (10,)\n"
     ]
    }
   ],
   "source": [
    "# 시간이 오래 걸리니 참고 기다리세요 !!!\n",
    "\n",
    "x = np.random.rand(100, 784)    # 더미 입력 데이터 (100장 분량)\n",
    "t = np.random.rand(100, 10)     # 더미 정답 레이블 (100장 분량)  => one-hot encoding이 아님 \n",
    "\n",
    "grads = net.numerical_gradient(x, t)    # 기울기 계산\n",
    "    \n",
    "print(\"grads['W1'].shape = \", grads['W1'].shape)    # (784, 50)\n",
    "print(\"grads['b1'].shape = \", grads['b1'].shape)    # (50,)\n",
    "print(\"grads['W2'].shape = \", grads['W2'].shape)    # (50, 10)\n",
    "print(\"grads['b2'].shape = \", grads['b2'].shape)    # (10,)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4.5.2 미니배치 학습 구현하기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mini-batch training Done!!!\n"
     ]
    }
   ],
   "source": [
    "# coding: utf-8\n",
    "import sys, os\n",
    "sys.path.append(os.pardir)  # 부모 디렉토리의 파일을 가져올 수 있도록 설정\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from dataset.mnist import load_mnist\n",
    "#from two_layer_net import TwoLayerNet\n",
    "\n",
    "# データの読み込み\n",
    "(x_train, t_train), (x_test, t_test) = load_mnist(normalize=True, one_hot_label=True)\n",
    "\n",
    "twolayernet = TwoLayerNet(input_size=784, hidden_size=50, output_size=10)\n",
    "\n",
    "# 하이퍼 파라미터\n",
    "iters_num = 10000  # 반복 횟수\n",
    "train_size = x_train.shape[0]\n",
    "batch_size = 100\n",
    "learning_rate = 0.1\n",
    "\n",
    "train_loss_list = []\n",
    "\n",
    "for i in range(iters_num):\n",
    "    #print(str(i) + \"-th iteration\")\n",
    "    \n",
    "    # 미니배치 획득\n",
    "    batch_mask = np.random.choice(train_size, batch_size)    # 0 ~ 60000-1 숫자 중에 랜덤하게 100개를 선택\n",
    "    x_batch = x_train[batch_mask]\n",
    "    t_batch = t_train[batch_mask]\n",
    "    \n",
    "    # 기울기 계산\n",
    "    #grad = twolayernet.numerical_gradient(x_batch, t_batch)    # 너무 느려서 사용하기 곤란 !!!\n",
    "    grad = twolayernet.gradient(x_batch, t_batch)      # numerical gradient 대신에 analytical gradient 사용, 구현은 5장에서 \n",
    "    \n",
    "    # 매개변수 경신\n",
    "    for key in ('W1', 'b1', 'W2', 'b2'):\n",
    "        twolayernet.params[key] -= learning_rate * grad[key]\n",
    "    \n",
    "    # 학습 경과 기록\n",
    "    loss = twolayernet.loss(x_batch, t_batch)\n",
    "    train_loss_list.append(loss)\n",
    "\n",
    "print(\"Mini-batch training Done!!!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "손실함수 값의 추이 : 왼쪽은 10,000회 반복까지의 추이, 오른쪽은 1,000회 반복까지의 추이"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![대체 텍스트](fig-4-11.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**실습문제**: 위의 그래프를 출력하는 파이썬 스크립트를 작성하시오."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.plot(train_loss_list)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.plot(train_loss_list[:1000])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4.5.3 시험 데이터로 평가하기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "i = 0 | train acc, test acc | 0.1125, 0.1135\n",
      "i = 600 | train acc, test acc | 0.7772666666666667, 0.7815\n",
      "i = 1200 | train acc, test acc | 0.8750333333333333, 0.8806\n",
      "i = 1800 | train acc, test acc | 0.8987333333333334, 0.899\n",
      "i = 2400 | train acc, test acc | 0.9082333333333333, 0.9103\n",
      "i = 3000 | train acc, test acc | 0.91515, 0.9172\n",
      "i = 3600 | train acc, test acc | 0.9202833333333333, 0.9229\n",
      "i = 4200 | train acc, test acc | 0.9251666666666667, 0.927\n",
      "i = 4800 | train acc, test acc | 0.9284, 0.9293\n",
      "i = 5400 | train acc, test acc | 0.9314166666666667, 0.932\n",
      "i = 6000 | train acc, test acc | 0.9337333333333333, 0.9346\n",
      "i = 6600 | train acc, test acc | 0.9364333333333333, 0.9368\n",
      "i = 7200 | train acc, test acc | 0.9396666666666667, 0.9403\n",
      "i = 7800 | train acc, test acc | 0.9405, 0.9417\n",
      "i = 8400 | train acc, test acc | 0.9426666666666667, 0.9425\n",
      "i = 9000 | train acc, test acc | 0.94555, 0.9449\n",
      "i = 9600 | train acc, test acc | 0.9469166666666666, 0.9458\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# coding: utf-8\n",
    "import sys, os\n",
    "sys.path.append(os.pardir)  # 부모 디렉토리의 파일을 가져올 수 있도록 설정\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from dataset.mnist import load_mnist\n",
    "#from two_layer_net import TwoLayerNet\n",
    "\n",
    "# データの読み込み\n",
    "(x_train, t_train), (x_test, t_test) = load_mnist(normalize=True, one_hot_label=True)\n",
    "\n",
    "twolayernet = TwoLayerNet(input_size=784, hidden_size=50, output_size=10)\n",
    "\n",
    "# 하이퍼 파라미터\n",
    "iters_num = 10000  # 繰り返しの回数を適宜設定する\n",
    "train_size = x_train.shape[0]\n",
    "batch_size = 100\n",
    "learning_rate = 0.1\n",
    "\n",
    "train_loss_list = []\n",
    "train_acc_list = []\n",
    "test_acc_list = []\n",
    "\n",
    "# 1 에폭당 반복수\n",
    "iter_per_epoch = max(train_size / batch_size, 1)\n",
    "# 1 에폭은 학습에서 훈련 데이터를 모두 소진했을 때의 횟수에 해당합니다.\n",
    "# 예컨데 훈련 데이터 10,000개를 100개의 미니배치로 학습할 경우, \n",
    "# 확률적 경사하강법을 100회 반복하면 모든 훈련 데이터를 소진하게 됩니다.\n",
    "# 이 경우 100회가 1 에폭이 됩니다.\n",
    "\n",
    "for i in range(iters_num):\n",
    "    # 미니배치 획득\n",
    "    batch_mask = np.random.choice(train_size, batch_size)\n",
    "    x_batch = x_train[batch_mask]\n",
    "    t_batch = t_train[batch_mask]\n",
    "    \n",
    "    # 기울기 계산\n",
    "    #grad = twolayernet.numerical_gradient(x_batch, t_batch)\n",
    "    grad = twolayernet.gradient(x_batch, t_batch)\n",
    "    \n",
    "    # 매개변수 갱신\n",
    "    for key in ('W1', 'b1', 'W2', 'b2'):\n",
    "        twolayernet.params[key] -= learning_rate * grad[key]\n",
    "    \n",
    "    # 학습경과 기록\n",
    "    loss = twolayernet.loss(x_batch, t_batch)\n",
    "    train_loss_list.append(loss)\n",
    "    \n",
    "    # 1 에폭당 정확도 계산\n",
    "    if i % iter_per_epoch == 0:\n",
    "        train_acc = twolayernet.accuracy(x_train, t_train)\n",
    "        test_acc = twolayernet.accuracy(x_test, t_test)\n",
    "        train_acc_list.append(train_acc)\n",
    "        test_acc_list.append(test_acc)\n",
    "        print(\"i = \" + str(i) + \" | train acc, test acc | \" + str(train_acc) + \", \" + str(test_acc))\n",
    "\n",
    "# グラフの描画\n",
    "markers = {'train': 'o', 'test': 's'}\n",
    "x = np.arange(len(train_acc_list))\n",
    "plt.plot(x, train_acc_list, label='train acc')\n",
    "plt.plot(x, test_acc_list, label='test acc', linestyle='--')\n",
    "plt.xlabel(\"epochs\")\n",
    "plt.ylabel(\"accuracy\")\n",
    "plt.ylim(0, 1.0)\n",
    "plt.legend(loc='lower right')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Overfiting(과적합): 훈련 데이터에 포함된 이미지만 제대로 구분하고, 테스트 데이터 등 다른 이미지는 잘 구분해 내지 못하는 현상\n",
    "\n",
    "- 위의 예제는 오버피팅 없이 훈련 데이터와 테스트 데이터에 모두 잘 동작하고 있음"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 눈으로 확인하기"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**실습문제**: 아래 그림과 같이 TwoLayerNet이 잘 동작하는지 테스트 데이터에서 무작위로 10개를 추출하여 prediction 한 결과를 눈으로 확인하는 프로그램을 작성하시오."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test_mask =  [3243   39 6839 8638 5004  297 1656 7427 1132 4441]\n",
      "y = 0            1            8            7            4            0            2            6            2            6            t = 0            1            8            7            4            0            2            6            2            6            "
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 1080x144 with 10 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from PIL import Image\n",
    "from matplotlib.pyplot import imshow\n",
    "%matplotlib inline  \n",
    "\n",
    "def img_show(img):\n",
    "    pil_img = Image.fromarray(np.uint8(img))\n",
    "    imshow(np.asarray(pil_img)) \n",
    "\n",
    "test_size = x_test.shape[0]\n",
    "test_mask = np.random.choice(test_size, 10)\n",
    "print(\"test_mask = \", test_mask)\n",
    "\n",
    "x = x_test[test_mask]\n",
    "t = t_test[test_mask]\n",
    "y = twolayernet.predict(x)\n",
    "\n",
    "y = np.argmax(y, axis=1)\n",
    "t = np.argmax(t, axis=1)\n",
    "\n",
    "print(\"y =\", end=\" \")\n",
    "for i in range(10):\n",
    "    label = y[i]\n",
    "    print(label, end=\"            \") \n",
    "\n",
    "print(\"t =\", end=\" \")\n",
    "for i in range(10):\n",
    "    label = t[i]\n",
    "    print(label, end=\"            \") \n",
    "        \n",
    "plt.figure(figsize=(15, 2)) \n",
    "plt.subplots_adjust(wspace=0.5, hspace=0.5)\n",
    "for i in range(10):\n",
    "    plt.subplot(1, 10, i + 1)\n",
    "    img = x[i]*256  \n",
    "    img = img.reshape(28, 28)  \n",
    "    img_show(img)\n",
    "plt.show()  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
