{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Chapter 5. 오차역전파법 (Back Propagation)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**실습문제**: 본 문서에 나오는 파이썬/넘파이 스크립트에서 None과 pass로 표시된 곳을 찾아서 적절한 코드로 대체하시오."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "가중치 매개변수에 대한 손실함수의 기울기를 구하는 방법:\n",
    "- 수치미분 : Chapter 4\n",
    "- 오차역전파 : Chapter 5\n",
    "\n",
    "오차역전파(back propagation) 구현 방법:\n",
    "- 수식을 이용하는 방법\n",
    "- 계산그래프를 이용하는 방법 (본 교재)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5.1 계산 그래프"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- 그래프 자료구조 : 노드(node)와 에지(edge)로 데이터를 표현 "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5.1.1 계산 그래프로 풀다"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "문제1: 현빈 군은 슈퍼에서 1개에 100원인 사과를 2개 샀습니다. 이때 지불 금액을 구하세요. 단, 소비세가 10% 부과됩니다.\n",
    "\n",
    "<img src=\"fig-5-2.png\" width=\"700\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "문제2: 현빈 군은 슈퍼에서 사과를 2개, 귤을 3개 샀습니다. 사과는 1개에 100원, 귤은 1개에 150원입니다. 소비세가 10%일 때 지불 금액을 구하세요.\n",
    "\n",
    "<img src=\"fig-5-3.png\" width=\"700\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "순전파(forward propagation) : 계산 그래프에서 계산을 왼쪽에서 오른쪽으로 진행"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5.1.2 국소적 계산"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "각 노드는 자신과 관련한 계산 외에는 아무것도 신경 쓸 게 없다.\n",
    "\n",
    "<img src=\"fig-5-4.png\" width=\"700\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5.1.3 왜 계산 그래프로 푸는가?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- 국소적 계산 : 전체 계산이 복잡하더라도 각 노드에서는 단순한 계산에 집중하여 문제를 단순화 할 수 있음\n",
    "- 중간 계산 결과를 보관할 수 있음\n",
    "- 역전파 때 미분을 효율적으로 계산할 수 있음"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "예) 사과 가격에 대한 지불 금액의 미분값을 역전파로 전달\n",
    "\n",
    "<img src=\"fig-5-5.png\" width=\"700\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5.2 연쇄 법칙 (chain rule)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5.2.1 계산 그래프의 역전파"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$y = f(x)$에 대한 역전파(back propagation) : 상류로 부터 전달된 값($E$)에 국소적 미분($\\frac{\\partial y}{\\partial x}$)을 곱하여 하류(앞쪽 노드)로 전달\n",
    "<img src=\"fig-5-6.png\" width=\"300\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5.2.2 연쇄법칙이란?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- 합성함수의 미분에 관한 법칙"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "아래의 식에 대한 미분을 구해보자:\n",
    "$$ z = \\big( x+y \\big)^2 $$ "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "위의 식은 아래의 두개의 식으로 나눌 수 있다:\n",
    "<img src=\"e-5.1.png\" width=\"100\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$\\frac{\\partial z}{\\partial x}$를 아래와 같이 국소적 미분(편미분)으로 나타낼 수 있다:\n",
    "<img src=\"e-5.2.png\" width=\"120\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "각 국소적 미분을 구하면:\n",
    "<img src=\"e-5.3.png\" width=\"80\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "연쇄법칙을 써서 국소적 미분을 곱하면:\n",
    "<img src=\"e-5.4.png\" width=\"250\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5.2.3 연쇄법칙과 계산 그래프"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "연쇄법칙을 계산그래프의 역전파로로 나타내면:\n",
    "<img src=\"fig-5-7.png\" width=\"500\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "5.2.2절의 식을 계산그래프에 대입하면:\n",
    "<img src=\"fig-5-8.png\" width=\"500\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5.3 역전파"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5.3.1 덧셈노드의 역전파"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$ z = x+y \\;\\; \\implies \\;\\; \\frac{\\partial z}{\\partial x} = 1 , \\frac{\\partial z}{\\partial y} = 1 $\n",
    "\n",
    "덧셈노드의 역전파는 입력값을 그대로 하류로 흘려보낸다.\n",
    "<img src=\"fig-5-9.png\" width=\"600\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5.3.2 곱셈노드의 역전파"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$ z = xy \\;\\; \\implies \\;\\; \\frac{\\partial z}{\\partial x} = y , \\frac{\\partial z}{\\partial y} = x $\n",
    "\n",
    "곱셈노드의 역전파는 입력고 신호들을 서로 바꾼 값을 곱해서 하류로 보낸다.\n",
    "<img src=\"fig-5-12.png\" width=\"600\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5.3.3 사과 쇼핑의 예"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"fig-5-14.png\" width=\"600\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**실습문제**: 아래는 사과와 귤 쇼핑에 대한 계산 그래프이다. 빈 상자 안에 적절한 숫자를 넣어 역전파를 완성하시오.\n",
    "\n",
    "<img src=\"fig-5-15.png\" width=\"700\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5.4 단순한 계층 구현하기"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5.4.1 곱셈 계층"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "class MulLayer:\n",
    "    def __init__(self):\n",
    "        self.x = None\n",
    "        self.y = None\n",
    "\n",
    "    def forward(self, x, y):\n",
    "        self.x = x    # x,y는 backward에서 사용하기 위해 저장\n",
    "        self.y = y                \n",
    "        out = x * y\n",
    "\n",
    "        return out\n",
    "\n",
    "    def backward(self, dout):\n",
    "        dx = dout * self.y\n",
    "        dy = dout * self.x\n",
    "\n",
    "        return dx, dy"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5.4.2 덧셈 계층"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "class AddLayer:\n",
    "    def __init__(self):\n",
    "        pass\n",
    "\n",
    "    def forward(self, x, y):\n",
    "        out = x + y\n",
    "\n",
    "        return out\n",
    "\n",
    "    def backward(self, dout):\n",
    "        dx = dout * 1\n",
    "        dy = dout * 1\n",
    "\n",
    "        return dx, dy"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5.5 활성화 함수 계층 구현하기"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5.5.1 ReLU 계층"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "ReLU 함수:\n",
    "<img src=\"e-5.7.png\" width=\"120\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "ReLU 함수의 미분:\n",
    "<img src=\"e-5.8.png\" width=\"140\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "ReLU 계층의 계산그래프:\n",
    "<img src=\"fig-5-18.png\" width=\"500\">"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# common/layers.py\n",
    "\n",
    "class Relu:\n",
    "    def __init__(self):\n",
    "        self.mask = None\n",
    "\n",
    "    def forward(self, x):\n",
    "        self.mask = (x <= 0)    # mask는 True/False로 구성된 넘파이 배열\n",
    "        out = x.copy()\n",
    "        out[self.mask] = 0\n",
    "\n",
    "        return out\n",
    "\n",
    "    def backward(self, dout):\n",
    "        dout[self.mask] = 0\n",
    "        dx = dout\n",
    "\n",
    "        return dx"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "위의 ReLU 클래스에서 mask라는 인스턴스 변수는 True/False로 구성된 넘파이 배수이다.\n",
    "mask 사용 예는 아래와 같다:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 1.  -0.5]\n",
      " [-2.   3. ]]\n",
      "[[False  True]\n",
      " [ True False]]\n",
      "[[1. 0.]\n",
      " [0. 3.]]\n"
     ]
    }
   ],
   "source": [
    "# mask 사용 예\n",
    "import numpy as np\n",
    "\n",
    "x = np.array( [ [1.0, -0.5], [-2.0, 3.0] ] )\n",
    "print(x)\n",
    "mask = (x <= 0)\n",
    "print(mask)\n",
    "x[mask] = 0\n",
    "print(x)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5.5.2 Sigmoid 계층"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Sigmoid 함수:\n",
    "<img src=\"e-5.9.png\" width=\"140\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Sigmoid 계층의 계산그래프:\n",
    "<img src=\"fig-5-20.png\" width=\"600\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Sigmoid 계층의 계산그래프 (간소화 버전):\n",
    "<img src=\"fig-5-21.png\" width=\"300\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "위의 계산그래프에 있는 수식을 정리하면:\n",
    "<img src=\"e-5.12.png\" width=\"350\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Sigmoid 계층의 계산그래프 (최종) : 순전파의 출력 $y$ 만으로 역전파를 계산할 수 있다\n",
    "<img src=\"fig-5-22.png\" width=\"300\">"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# common/layers.py\n",
    "from common.functions import *\n",
    "\n",
    "class Sigmoid:\n",
    "    def __init__(self):\n",
    "        self.out = None\n",
    "\n",
    "    def forward(self, x):\n",
    "        out = sigmoid(x)\n",
    "        self.out = out\n",
    "        return out\n",
    "\n",
    "    def backward(self, dout):\n",
    "        dx = dout * (1.0 - self.out) * self.out\n",
    "\n",
    "        return dx"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5.6 Affine/Softmax 계층 구현하기"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5.6.1 Affine 계층"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Affine Transformation : Y = np.dot(X,W) + B"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Affine 계층의 계산그래프 (순전파): 변수가 다차원 배열임\n",
    "<img src=\"fig-5-24.png\" width=\"300\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "행렬곱(dot)에 대한 역전파 : $\\textbf{X}, \\textbf{W}$에 대한 편미분\n",
    "<img src=\"e-5.13.png\" width=\"150\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "행렬곱(dot 노드)에 대한 계산그래프 (역전파): $\\textbf{X}$와 $\\frac{\\partial L}{\\partial \\textbf{X}}$의 형상은 일치해야 함\n",
    "<img src=\"fig-5-26.png\" width=\"400\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Affine 계층의 계산그래프 (역전파): \n",
    "<img src=\"fig-5-25.png\" width=\"500\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5.6.2 배치용 Affine 계층"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "배치용 Affine 계층의 계산그래프 : \n",
    "- $\\textbf{X}$와 $\\frac{\\partial L}{\\partial \\textbf{X}}$의 형상이 (N,2)로 바뀜\n",
    "- $\\frac{\\partial L}{\\partial \\textbf{X}}$과 $\\frac{\\partial L}{\\partial \\textbf{W}}$는 행렬의 형상만 고려하면 5.6.1절의 식과 같음 \n",
    "- $\\frac{\\partial L}{\\partial \\textbf{B}}$를 구할 때는 주의가 필요함\n",
    "<img src=\"fig-5-27.png\" width=\"500\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "순전파일 때 $\\textbf{B}$는 $\\textbf{X} \\cdot \\textbf{W}$의 각 데이터에 더해진다. 아래는 그 예이다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 1,  2,  3],\n",
       "       [11, 12, 13]])"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_dot_W = np.array( [ [0, 0, 0], [10, 10, 10] ] )\n",
    "B = np.array([1, 2, 3])\n",
    "X_dot_W + B"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "따라서 역전파 때는 각 데이터의 역전파 값이 $\\textbf{B}$의 역전파로 모여야 한다. 즉, $\\frac{\\partial L}{\\partial \\textbf{B}}$로 모여야 한다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([5, 7, 9])"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dY = np.array( [ [1,2,3], [4,5,6] ] )\n",
    "dB = np.sum(dY, axis=0)\n",
    "dB"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# common/layers.py\n",
    "\n",
    "class Affine:\n",
    "    def __init__(self, W, b):\n",
    "        self.W = W\n",
    "        self.b = b\n",
    "        self.x = None\n",
    "        self.dW = None\n",
    "        self.db = None\n",
    "\n",
    "    def forward(self, x):\n",
    "        self.x = x\n",
    "        out = np.dot(self.x, self.W) + self.b\n",
    "\n",
    "        return out\n",
    "\n",
    "    def backward(self, dout):\n",
    "        dx = np.dot(dout, self.W.T)\n",
    "        self.dW = np.dot(self.x.T, dout)\n",
    "        self.db = np.sum(dout, axis=0)\n",
    "        \n",
    "        return dx"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5.6.3 Softmax-with-Loss 계층"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "소프트맥스 함수는 입력 값을 정규화(출력의 합이 1이 되도록 변형)하여 출력한다.\n",
    "\n",
    "$$ y_k = \\frac{\\exp(a_k)}{\\sum_{i=1}^n \\exp(a_i)} $$\n",
    "<img src=\"fig-5-28.png\" width=\"600\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Softmax-with-Loss 계층의 계산그래프:\n",
    "\n",
    "$$ CEE = - \\sum_k t_{k} \\log y_{k} $$\n",
    "$$ CEE(batch) = - \\frac{1}{N} \\sum_n \\sum_k t_{nk} \\log y_{nk} $$\n",
    "<img src=\"fig-5-29.png\" width=\"800\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Softmax-with-Loss 계층의 계산그래프 (간소화 버전):\n",
    "<img src=\"fig-5-30.png\" width=\"600\">"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# common/layers.py\n",
    "from common.functions import *\n",
    "\n",
    "class SoftmaxWithLoss:\n",
    "    def __init__(self):\n",
    "        self.loss = None  # 손실\n",
    "        self.y = None     # softmax의 출력\n",
    "        self.t = None     # 정답 레이블 (원-핫 벡터)\n",
    "\n",
    "    def forward(self, x, t):\n",
    "        self.t = t\n",
    "        self.y = softmax(x)\n",
    "        self.loss = cross_entropy_error(self.y, self.t)\n",
    "        \n",
    "        return self.loss\n",
    "\n",
    "    def backward(self, dout=1):\n",
    "        batch_size = self.t.shape[0]\n",
    "        dx = (self.y - self.t) / batch_size    # 데이터 1개당 오차를 앞 계층으로 전파\n",
    "        \n",
    "        return dx\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5.7 오차역전파법 구현하기"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5.7.1 신경망 학습의 전체 그림"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"p180.JPG\" width=\"800\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5.7.2 오차역전파법을 적용한 신경망 구현하기"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"p181.JPG\" width=\"800\">"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "# coding: utf-8\n",
    "import sys, os\n",
    "sys.path.append(os.pardir)  \n",
    "import numpy as np\n",
    "from common.layers import *\n",
    "from common.gradient import numerical_gradient\n",
    "from collections import OrderedDict\n",
    "\n",
    "class TwoLayerNet:\n",
    "\n",
    "    def __init__(self, input_size, hidden_size, output_size, weight_init_std = 0.01):\n",
    "        # 가중치 초기화\n",
    "        self.params = {}\n",
    "        self.params['W1'] = weight_init_std * np.random.randn(input_size, hidden_size)\n",
    "        self.params['b1'] = np.zeros(hidden_size)\n",
    "        self.params['W2'] = weight_init_std * np.random.randn(hidden_size, output_size) \n",
    "        self.params['b2'] = np.zeros(output_size)\n",
    "\n",
    "        # 계층 생성 \n",
    "        self.layers = OrderedDict()    # 순서가 있는 딕셔너리 \n",
    "        self.layers['Affine1'] = Affine(self.params['W1'], self.params['b1'])\n",
    "        self.layers['Relu1'] = Relu()\n",
    "        #self.layers['Sigmoid1'] = Sigmoid()    # ReLU 대신 Sigmoid로 하면?\n",
    "        self.layers['Affine2'] = Affine(self.params['W2'], self.params['b2'])\n",
    "\n",
    "        self.lastLayer = SoftmaxWithLoss()\n",
    "        \n",
    "    def predict(self, x):\n",
    "        for layer in self.layers.values():\n",
    "            x = layer.forward(x)\n",
    "        \n",
    "        return x\n",
    "        \n",
    "    # x:입력 데이터, t:정답 레이블 \n",
    "    def loss(self, x, t):\n",
    "        y = self.predict(x)\n",
    "        return self.lastLayer.forward(y, t)\n",
    "    \n",
    "    def accuracy(self, x, t):\n",
    "        y = self.predict(x)\n",
    "        y = np.argmax(y, axis=1)\n",
    "        if t.ndim != 1 : t = np.argmax(t, axis=1)\n",
    "        \n",
    "        accuracy = np.sum(y == t) / float(x.shape[0])\n",
    "        return accuracy\n",
    "        \n",
    "    # x:입력 데이터, t:정답 레이블\n",
    "    def numerical_gradient(self, x, t):\n",
    "        loss_W = lambda W: self.loss(x, t)\n",
    "        \n",
    "        grads = {}\n",
    "        grads['W1'] = numerical_gradient(loss_W, self.params['W1'])\n",
    "        grads['b1'] = numerical_gradient(loss_W, self.params['b1'])\n",
    "        grads['W2'] = numerical_gradient(loss_W, self.params['W2'])\n",
    "        grads['b2'] = numerical_gradient(loss_W, self.params['b2'])\n",
    "        \n",
    "        return grads\n",
    "        \n",
    "    def gradient(self, x, t):\n",
    "        # forward\n",
    "        self.loss(x, t)\n",
    "\n",
    "        # backward\n",
    "        dout = 1\n",
    "        dout = self.lastLayer.backward(dout)\n",
    "        \n",
    "        layers = list(self.layers.values())\n",
    "        layers.reverse()\n",
    "        for layer in layers:\n",
    "            dout = layer.backward(dout)\n",
    "\n",
    "        # 결과 저장\n",
    "        grads = {}\n",
    "        grads['W1'], grads['b1'] = self.layers['Affine1'].dW, self.layers['Affine1'].db\n",
    "        grads['W2'], grads['b2'] = self.layers['Affine2'].dW, self.layers['Affine2'].db\n",
    "\n",
    "        return grads\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5.7.3 오차역전파법으로 구한 기울기 검증하기"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- 생략 (교재를 참조하세요)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5.7.4 오차역전파법을 사용한 학습 구현하기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 0.16256666666666666 0.1665\n",
      "600 0.9055333333333333 0.9102\n",
      "1200 0.9196333333333333 0.9209\n",
      "1800 0.933 0.9333\n",
      "2400 0.9428 0.9403\n",
      "3000 0.9481 0.9458\n",
      "3600 0.9541333333333334 0.9512\n",
      "4200 0.95695 0.9529\n",
      "4800 0.9628833333333333 0.9587\n",
      "5400 0.9638833333333333 0.9585\n",
      "6000 0.9682666666666667 0.9635\n",
      "6600 0.9691166666666666 0.9631\n",
      "7200 0.9722 0.9641\n",
      "7800 0.9735 0.9648\n",
      "8400 0.9753833333333334 0.967\n",
      "9000 0.9767 0.9686\n",
      "9600 0.9784666666666667 0.9686\n"
     ]
    }
   ],
   "source": [
    "# coding: utf-8\n",
    "import sys, os\n",
    "sys.path.append(os.pardir)\n",
    "import numpy as np\n",
    "from dataset.mnist import load_mnist\n",
    "#from two_layer_net import TwoLayerNet\n",
    "\n",
    "# 데이터 읽기 \n",
    "(x_train, t_train), (x_test, t_test) = load_mnist(normalize=True, one_hot_label=True)\n",
    "\n",
    "network = TwoLayerNet(input_size=784, hidden_size=50, output_size=10)\n",
    "\n",
    "iters_num = 10000\n",
    "train_size = x_train.shape[0]\n",
    "batch_size = 100\n",
    "learning_rate = 0.1\n",
    "\n",
    "train_loss_list = []\n",
    "train_acc_list = []\n",
    "test_acc_list = []\n",
    "\n",
    "iter_per_epoch = max(train_size / batch_size, 1)\n",
    "\n",
    "for i in range(iters_num):\n",
    "    batch_mask = np.random.choice(train_size, batch_size)\n",
    "    x_batch = x_train[batch_mask]\n",
    "    t_batch = t_train[batch_mask]\n",
    "    \n",
    "    # 기울기 구하기 \n",
    "    #grad = network.numerical_gradient(x_batch, t_batch)\n",
    "    grad = network.gradient(x_batch, t_batch)\n",
    "    \n",
    "    # 매개변수 갱신 \n",
    "    for key in ('W1', 'b1', 'W2', 'b2'):\n",
    "        network.params[key] -= learning_rate * grad[key]\n",
    "    \n",
    "    loss = network.loss(x_batch, t_batch)\n",
    "    train_loss_list.append(loss)\n",
    "    \n",
    "    if i % iter_per_epoch == 0:\n",
    "        train_acc = network.accuracy(x_train, t_train)\n",
    "        test_acc = network.accuracy(x_test, t_test)\n",
    "        train_acc_list.append(train_acc)\n",
    "        test_acc_list.append(test_acc)\n",
    "        print(i, train_acc, test_acc)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "markers = {'train': 'o', 'test': 's'}\n",
    "x = np.arange(len(train_acc_list))\n",
    "plt.plot(x, train_acc_list, label='train acc')\n",
    "plt.plot(x, test_acc_list, label='test acc', linestyle='--')\n",
    "plt.xlabel(\"epochs\")\n",
    "plt.ylabel(\"accuracy\")\n",
    "plt.ylim(0, 1.0)\n",
    "plt.legend(loc='lower right')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**실습문제1**: 5.7절의 2층 신경망을 3층 신경망으로 확장하여 구현하고 그 결과를 2층 신경망과 비교하시오. 단, hidden layer1의 뉴런 수는 50개, hidden layer2의 뉴런 수는 100개로 하시오. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**실습문제2**: MNIST 데이터를 이용하여 3.6절에 있는 3층 신경망의 매개변수를 학습하여 구현하시오. 구현된 결과를 3.6절의 정확도와 비교하고, 4.5절의 2층 신경망과도 학습시간과 정확도를 비교하시오. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
