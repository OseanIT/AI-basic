{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Chapter 5. 오차역전파법 (Back Propagation)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**실습문제**: 본 문서에 나오는 파이썬/넘파이 스크립트에서 None과 pass로 표시된 곳을 찾아서 적절한 코드로 대체하시오."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "가중치 매개변수에 대한 손실함수의 기울기를 구하는 방법:\n",
    "- 수치미분 : Chapter 4\n",
    "- 오차역전파 : Chapter 5\n",
    "\n",
    "오차역전파(back propagation) 구현 방법:\n",
    "- 수식을 이용하는 방법\n",
    "- 계산그래프를 이용하는 방법 (본 교재)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5.1 계산 그래프"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- 그래프 자료구조 : 노드(node)와 에지(edge)로 데이터를 표현 "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5.1.1 계산 그래프로 풀다"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "문제1: 현빈 군은 슈퍼에서 1개에 100원인 사과를 2개 샀습니다. 이때 지불 금액을 구하세요. 단, 소비세가 10% 부과됩니다.\n",
    "\n",
    "<img src=\"fig-5-2.png\" width=\"700\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "문제2: 현빈 군은 슈퍼에서 사과를 2개, 귤을 3개 샀습니다. 사과는 1개에 100원, 귤은 1개에 150원입니다. 소비세가 10%일 때 지불 금액을 구하세요.\n",
    "\n",
    "<img src=\"fig-5-3.png\" width=\"700\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "순전파(forward propagation) : 계산 그래프에서 계산을 왼쪽에서 오른쪽으로 진행"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5.1.2 국소적 계산"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "각 노드는 자신과 관련한 계산 외에는 아무것도 신경 쓸 게 없다.\n",
    "\n",
    "<img src=\"fig-5-4.png\" width=\"700\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5.1.3 왜 계산 그래프로 푸는가?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- 국소적 계산 : 전체 계산이 복잡하더라도 각 노드에서는 단순한 계산에 집중하여 문제를 단순화 할 수 있음\n",
    "- 중간 계산 결과를 보관할 수 있음\n",
    "- 역전파 때 미분을 효율적으로 계산할 수 있음"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "예) 사과 가격에 대한 지불 금액의 미분값을 역전파로 전달\n",
    "\n",
    "<img src=\"fig-5-5.png\" width=\"700\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5.2 연쇄 법칙 (chain rule)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5.2.1 계산 그래프의 역전파"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$y = f(x)$에 대한 역전파(back propagation) : 상류로 부터 전달된 값($E$)에 국소적 미분($\\frac{\\partial y}{\\partial x}$)을 곱하여 하류(앞쪽 노드)로 전달\n",
    "<img src=\"fig-5-6.png\" width=\"300\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5.2.2 연쇄법칙이란?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- 합성함수의 미분에 관한 법칙"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "아래의 식에 대한 미분을 구해보자:\n",
    "$$ z = \\big( x+y \\big)^2 $$ "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "위의 식은 아래의 두개의 식으로 나눌 수 있다:\n",
    "<img src=\"e-5.1.png\" width=\"100\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$\\frac{\\partial z}{\\partial x}$를 아래와 같이 국소적 미분(편미분)으로 나타낼 수 있다:\n",
    "<img src=\"e-5.2.png\" width=\"120\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "각 국소적 미분을 구하면:\n",
    "<img src=\"e-5.3.png\" width=\"80\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "연쇄법칙을 써서 국소적 미분을 곱하면:\n",
    "<img src=\"e-5.4.png\" width=\"250\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5.2.3 연쇄법칙과 계산 그래프"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "연쇄법칙을 계산그래프의 역전파로로 나타내면:\n",
    "<img src=\"fig-5-7.png\" width=\"500\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "5.2.2절의 식을 계산그래프에 대입하면:\n",
    "<img src=\"fig-5-8.png\" width=\"500\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5.3 역전파"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5.3.1 덧셈노드의 역전파"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$ z = x+y \\;\\; \\implies \\;\\; \\frac{\\partial z}{\\partial x} = 1 , \\frac{\\partial z}{\\partial y} = 1 $\n",
    "\n",
    "덧셈노드의 역전파는 입력값을 그대로 하류로 흘려보낸다.\n",
    "<img src=\"fig-5-9.png\" width=\"600\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5.3.2 곱셈노드의 역전파"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$ z = xy \\;\\; \\implies \\;\\; \\frac{\\partial z}{\\partial x} = y , \\frac{\\partial z}{\\partial y} = x $\n",
    "\n",
    "곱셈노드의 역전파는 입력고 신호들을 서로 바꾼 값을 곱해서 하류로 보낸다.\n",
    "<img src=\"fig-5-12.png\" width=\"600\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5.3.3 사과 쇼핑의 예"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"fig-5-14.png\" width=\"600\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**실습문제**: 아래는 사과와 귤 쇼핑에 대한 계산 그래프이다. 빈 상자 안에 적절한 숫자를 넣어 역전파를 완성하시오.\n",
    "\n",
    "<img src=\"fig-5-15.png\" width=\"700\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5.4 단순한 계층 구현하기"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5.4.1 곱셈 계층"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "class MulLayer:\n",
    "    def __init__(self):\n",
    "        self.x = None\n",
    "        self.y = None\n",
    "\n",
    "    def forward(self, x, y):\n",
    "        self.x = x    # x,y는 backward에서 사용하기 위해 저장\n",
    "        self.y = y                \n",
    "        out = x * y\n",
    "\n",
    "        return out\n",
    "\n",
    "    def backward(self, dout):\n",
    "        dx = dout * self.y\n",
    "        dy = dout * self.x\n",
    "\n",
    "        return dx, dy"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5.4.2 덧셈 계층"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "class AddLayer:\n",
    "    def __init__(self):\n",
    "        pass\n",
    "\n",
    "    def forward(self, x, y):\n",
    "        out = x + y\n",
    "\n",
    "        return out\n",
    "\n",
    "    def backward(self, dout):\n",
    "        dx = dout * 1\n",
    "        dy = dout * 1\n",
    "\n",
    "        return dx, dy"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5.5 활성화 함수 계층 구현하기"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5.5.1 ReLU 계층"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "ReLU 함수:\n",
    "<img src=\"e-5.7.png\" width=\"120\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "ReLU 함수의 미분:\n",
    "<img src=\"e-5.8.png\" width=\"140\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "ReLU 계층의 계산그래프:\n",
    "<img src=\"fig-5-18.png\" width=\"500\">"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# common/layers.py\n",
    "\n",
    "class Relu:\n",
    "    def __init__(self):\n",
    "        self.mask = None\n",
    "\n",
    "    def forward(self, x):\n",
    "        self.mask = (x <= 0)    # mask는 True/False로 구성된 넘파이 배열\n",
    "        out = x.copy()\n",
    "        out[self.mask] = 0\n",
    "\n",
    "        return out\n",
    "\n",
    "    def backward(self, dout):\n",
    "        dout[self.mask] = 0\n",
    "        dx = dout\n",
    "\n",
    "        return dx"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "위의 ReLU 클래스에서 mask라는 인스턴스 변수는 True/False로 구성된 넘파이 배수이다.\n",
    "mask 사용 예는 아래와 같다:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 1.  -0.5]\n",
      " [-2.   3. ]]\n",
      "[[False  True]\n",
      " [ True False]]\n",
      "[[1. 0.]\n",
      " [0. 3.]]\n"
     ]
    }
   ],
   "source": [
    "# mask 사용 예\n",
    "import numpy as np\n",
    "\n",
    "x = np.array( [ [1.0, -0.5], [-2.0, 3.0] ] )\n",
    "print(x)\n",
    "mask = (x <= 0)\n",
    "print(mask)\n",
    "x[mask] = 0\n",
    "print(x)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5.5.2 Sigmoid 계층"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Sigmoid 함수:\n",
    "<img src=\"e-5.9.png\" width=\"140\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Sigmoid 계층의 계산그래프:\n",
    "<img src=\"fig-5-20.png\" width=\"600\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Sigmoid 계층의 계산그래프 (간소화 버전):\n",
    "<img src=\"fig-5-21.png\" width=\"300\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "위의 계산그래프에 있는 수식을 정리하면:\n",
    "<img src=\"e-5.12.png\" width=\"350\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Sigmoid 계층의 계산그래프 (최종) : 순전파의 출력 $y$ 만으로 역전파를 계산할 수 있다\n",
    "<img src=\"fig-5-22.png\" width=\"300\">"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# common/layers.py\n",
    "from common.functions import *\n",
    "\n",
    "class Sigmoid:\n",
    "    def __init__(self):\n",
    "        self.out = None\n",
    "\n",
    "    def forward(self, x):\n",
    "        out = sigmoid(x)\n",
    "        self.out = out\n",
    "        return out\n",
    "\n",
    "    def backward(self, dout):\n",
    "        dx = dout * (1.0 - self.out) * self.out\n",
    "\n",
    "        return dx"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5.6 Affine/Softmax 계층 구현하기"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5.6.1 Affine 계층"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Affine Transformation : Y = np.dot(X,W) + B"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Affine 계층의 계산그래프 (순전파): 변수가 다차원 배열임\n",
    "<img src=\"fig-5-24.png\" width=\"300\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "행렬곱(dot)에 대한 역전파 : $\\textbf{X}, \\textbf{W}$에 대한 편미분\n",
    "<img src=\"e-5.13.png\" width=\"150\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "행렬곱(dot 노드)에 대한 계산그래프 (역전파): $\\textbf{X}$와 $\\frac{\\partial L}{\\partial \\textbf{X}}$의 형상은 일치해야 함\n",
    "<img src=\"fig-5-26.png\" width=\"400\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Affine 계층의 계산그래프 (역전파): \n",
    "<img src=\"fig-5-25.png\" width=\"500\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5.6.2 배치용 Affine 계층"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "배치용 Affine 계층의 계산그래프 : \n",
    "- $\\textbf{X}$와 $\\frac{\\partial L}{\\partial \\textbf{X}}$의 형상이 (N,2)로 바뀜\n",
    "- $\\frac{\\partial L}{\\partial \\textbf{X}}$과 $\\frac{\\partial L}{\\partial \\textbf{W}}$는 행렬의 형상만 고려하면 5.6.1절의 식과 같음 \n",
    "- $\\frac{\\partial L}{\\partial \\textbf{B}}$를 구할 때는 주의가 필요함\n",
    "<img src=\"fig-5-27.png\" width=\"500\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "순전파일 때 $\\textbf{B}$는 $\\textbf{X} \\cdot \\textbf{W}$의 각 데이터에 더해진다. 아래는 그 예이다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 1,  2,  3],\n",
       "       [11, 12, 13]])"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_dot_W = np.array( [ [0, 0, 0], [10, 10, 10] ] )\n",
    "B = np.array([1, 2, 3])\n",
    "X_dot_W + B"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "따라서 역전파 때는 각 데이터의 역전파 값이 $\\textbf{B}$의 역전파로 모여야 한다. 즉, $\\frac{\\partial L}{\\partial \\textbf{B}}$로 모여야 한다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([5, 7, 9])"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dY = np.array( [ [1,2,3], [4,5,6] ] )\n",
    "dB = np.sum(dY, axis=0)\n",
    "dB"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# common/layers.py\n",
    "\n",
    "class Affine:\n",
    "    def __init__(self, W, b):\n",
    "        self.W = W\n",
    "        self.b = b\n",
    "        self.x = None\n",
    "        self.dW = None\n",
    "        self.db = None\n",
    "\n",
    "    def forward(self, x):\n",
    "        self.x = x\n",
    "        out = np.dot(self.x, self.W) + self.b\n",
    "\n",
    "        return out\n",
    "\n",
    "    def backward(self, dout):\n",
    "        dx = np.dot(dout, self.W.T)\n",
    "        self.dW = np.dot(self.x.T, dout)\n",
    "        self.db = np.sum(dout, axis=0)\n",
    "        \n",
    "        return dx"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5.6.3 Softmax-with-Loss 계층"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "소프트맥스 함수는 입력 값을 정규화(출력의 합이 1이 되도록 변형)하여 출력한다.\n",
    "\n",
    "$$ y_k = \\frac{\\exp(a_k)}{\\sum_{i=1}^n \\exp(a_i)} $$\n",
    "<img src=\"fig-5-28.png\" width=\"600\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Softmax-with-Loss 계층의 계산그래프:\n",
    "\n",
    "$$ CEE = - \\sum_k t_{k} \\log y_{k} $$\n",
    "$$ CEE(batch) = - \\frac{1}{N} \\sum_n \\sum_k t_{nk} \\log y_{nk} $$\n",
    "<img src=\"fig-5-29.png\" width=\"800\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Softmax-with-Loss 계층의 계산그래프 (간소화 버전):\n",
    "<img src=\"fig-5-30.png\" width=\"600\">"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# common/layers.py\n",
    "from common.functions import *\n",
    "\n",
    "class SoftmaxWithLoss:\n",
    "    def __init__(self):\n",
    "        self.loss = None  # 손실\n",
    "        self.y = None     # softmax의 출력\n",
    "        self.t = None     # 정답 레이블 (원-핫 벡터)\n",
    "\n",
    "    def forward(self, x, t):\n",
    "        self.t = t\n",
    "        self.y = softmax(x)\n",
    "        self.loss = cross_entropy_error(self.y, self.t)\n",
    "        \n",
    "        return self.loss\n",
    "\n",
    "    def backward(self, dout=1):\n",
    "        batch_size = self.t.shape[0]\n",
    "        dx = (self.y - self.t) / batch_size    # 데이터 1개당 오차를 앞 계층으로 전파\n",
    "        \n",
    "        return dx\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5.7 오차역전파법 구현하기"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5.7.1 신경망 학습의 전체 그림"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"p180.JPG\" width=\"800\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5.7.2 오차역전파법을 적용한 신경망 구현하기"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"p181.JPG\" width=\"800\">"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# coding: utf-8\n",
    "import sys, os\n",
    "sys.path.append(os.pardir)  \n",
    "import numpy as np\n",
    "from common.layers import *\n",
    "from common.gradient import numerical_gradient\n",
    "from collections import OrderedDict\n",
    "\n",
    "class TwoLayerNet:\n",
    "\n",
    "    def __init__(self, input_size, hidden_size, output_size, weight_init_std = 0.01):\n",
    "        # 가중치 초기화\n",
    "        self.params = {}\n",
    "        self.params['W1'] = weight_init_std * np.random.randn(input_size, hidden_size)\n",
    "        self.params['b1'] = np.zeros(hidden_size)\n",
    "        self.params['W2'] = weight_init_std * np.random.randn(hidden_size, output_size) \n",
    "        self.params['b2'] = np.zeros(output_size)\n",
    "\n",
    "        # 계층 생성 \n",
    "        self.layers = OrderedDict()    # 순서가 있는 딕셔너리 \n",
    "        self.layers['Affine1'] = Affine(self.params['W1'], self.params['b1'])\n",
    "        self.layers['Relu1'] = Relu()\n",
    "        #self.layers['Sigmoid1'] = Sigmoid()    # ReLU 대신 Sigmoid로 하면?\n",
    "        self.layers['Affine2'] = Affine(self.params['W2'], self.params['b2'])\n",
    "\n",
    "        self.lastLayer = SoftmaxWithLoss()\n",
    "        \n",
    "    def predict(self, x):\n",
    "        for layer in self.layers.values():\n",
    "            x = layer.forward(x)\n",
    "        \n",
    "        return x\n",
    "        \n",
    "    # x:입력 데이터, t:정답 레이블 \n",
    "    def loss(self, x, t):\n",
    "        y = self.predict(x)\n",
    "        return self.lastLayer.forward(y, t)\n",
    "    \n",
    "    def accuracy(self, x, t):\n",
    "        y = self.predict(x)\n",
    "        y = np.argmax(y, axis=1)\n",
    "        if t.ndim != 1 : t = np.argmax(t, axis=1)\n",
    "        \n",
    "        accuracy = np.sum(y == t) / float(x.shape[0])\n",
    "        return accuracy\n",
    "        \n",
    "    # x:입력 데이터, t:정답 레이블\n",
    "    def numerical_gradient(self, x, t):\n",
    "        loss_W = lambda W: self.loss(x, t)\n",
    "        \n",
    "        grads = {}\n",
    "        grads['W1'] = numerical_gradient(loss_W, self.params['W1'])\n",
    "        grads['b1'] = numerical_gradient(loss_W, self.params['b1'])\n",
    "        grads['W2'] = numerical_gradient(loss_W, self.params['W2'])\n",
    "        grads['b2'] = numerical_gradient(loss_W, self.params['b2'])\n",
    "        \n",
    "        return grads\n",
    "        \n",
    "    def gradient(self, x, t):\n",
    "        # forward\n",
    "        self.loss(x, t)\n",
    "\n",
    "        # backward\n",
    "        dout = 1\n",
    "        dout = self.lastLayer.backward(dout)\n",
    "        \n",
    "        layers = list(self.layers.values())\n",
    "        layers.reverse()\n",
    "        for layer in layers:\n",
    "            dout = layer.backward(dout)\n",
    "\n",
    "        # 결과 저장\n",
    "        grads = {}\n",
    "        grads['W1'], grads['b1'] = self.layers['Affine1'].dW, self.layers['Affine1'].db\n",
    "        grads['W2'], grads['b2'] = self.layers['Affine2'].dW, self.layers['Affine2'].db\n",
    "\n",
    "        return grads\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5.7.3 오차역전파법으로 구한 기울기 검증하기"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- 생략 (교재를 참조하세요)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5.7.4 오차역전파법을 사용한 학습 구현하기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 0.10313333333333333 0.1014\n",
      "600 0.90165 0.9051\n",
      "1200 0.9225833333333333 0.925\n",
      "1800 0.9350833333333334 0.935\n",
      "2400 0.9435666666666667 0.9428\n",
      "3000 0.9510666666666666 0.9498\n",
      "3600 0.95635 0.9552\n",
      "4200 0.9603666666666667 0.958\n",
      "4800 0.9642666666666667 0.9614\n",
      "5400 0.9657166666666667 0.9646\n",
      "6000 0.96845 0.9661\n",
      "6600 0.97095 0.9658\n",
      "7200 0.9734666666666667 0.9674\n",
      "7800 0.97345 0.9687\n",
      "8400 0.97715 0.9703\n",
      "9000 0.9788666666666667 0.9702\n",
      "9600 0.979 0.9707\n"
     ]
    }
   ],
   "source": [
    "# coding: utf-8\n",
    "import sys, os\n",
    "sys.path.append(os.pardir)\n",
    "import numpy as np\n",
    "from dataset.mnist import load_mnist\n",
    "#from two_layer_net import TwoLayerNet\n",
    "\n",
    "# 데이터 읽기 \n",
    "(x_train, t_train), (x_test, t_test) = load_mnist(normalize=True, one_hot_label=True)\n",
    "\n",
    "network = TwoLayerNet(input_size=784, hidden_size=50, output_size=10)\n",
    "\n",
    "iters_num = 10000\n",
    "train_size = x_train.shape[0]\n",
    "batch_size = 100\n",
    "learning_rate = 0.1\n",
    "\n",
    "train_loss_list = []\n",
    "train_acc_list = []\n",
    "test_acc_list = []\n",
    "\n",
    "iter_per_epoch = max(train_size / batch_size, 1)\n",
    "\n",
    "for i in range(iters_num):\n",
    "    batch_mask = np.random.choice(train_size, batch_size)\n",
    "    x_batch = x_train[batch_mask]\n",
    "    t_batch = t_train[batch_mask]\n",
    "    \n",
    "    # 기울기 구하기 \n",
    "    #grad = network.numerical_gradient(x_batch, t_batch)\n",
    "    grad = network.gradient(x_batch, t_batch)\n",
    "    \n",
    "    # 매개변수 갱신 \n",
    "    for key in ('W1', 'b1', 'W2', 'b2'):\n",
    "        network.params[key] -= learning_rate * grad[key]\n",
    "    \n",
    "    loss = network.loss(x_batch, t_batch)\n",
    "    train_loss_list.append(loss)\n",
    "    \n",
    "    if i % iter_per_epoch == 0:\n",
    "        train_acc = network.accuracy(x_train, t_train)\n",
    "        test_acc = network.accuracy(x_test, t_test)\n",
    "        train_acc_list.append(train_acc)\n",
    "        test_acc_list.append(test_acc)\n",
    "        print(i, train_acc, test_acc)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "markers = {'train': 'o', 'test': 's'}\n",
    "x = np.arange(len(train_acc_list))\n",
    "plt.plot(x, train_acc_list, label='train acc')\n",
    "plt.plot(x, test_acc_list, label='test acc', linestyle='--')\n",
    "plt.xlabel(\"epochs\")\n",
    "plt.ylabel(\"accuracy\")\n",
    "plt.ylim(0, 1.0)\n",
    "plt.legend(loc='lower right')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**실습문제1**: 5.7절의 2층 신경망을 3층 신경망으로 확장하여 구현하고 그 결과를 2층 신경망과 비교하시오. 단, hidden layer1의 뉴런 수는 50개, hidden layer2의 뉴런 수는 100개로 하시오. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**실습문제2**: MNIST 데이터를 이용하여 3.6절에 있는 3층 신경망의 매개변수를 학습하여 구현하시오. 구현된 결과를 3.6절의 정확도와 비교하고, 4.5절의 2층 신경망과도 학습시간과 정확도를 비교하시오. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
